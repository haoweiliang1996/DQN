/usr/bin/python3.5 /home/haowei/PycharmProjects/DQN/four.py
fig size: 80.0 DPI, size in inches [ 3.  4.]
env init ok
episode:20000,stepTimes:1200,stepSize:0.05,gbest: False,Ok_eps:1.0,init_state: [0.4, 35, 0.2, 0.3],agent_saved:True range: [30, 50]
episode:  0 Evaluation Average Reward: -16.138844255905965 avg distance 472.47443955055667 mini_state: [0.4, 36.09999999999994, 1.3000000000000005, 1.4000000000000006] mini_distance: 438.028433985708
/home/haowei/.local/lib/python3.5/site-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented
  warnings.warn(str, mplDeprecation)
episode:  100 Evaluation Average Reward: -3.9116540253677385 avg distance 57.69822740314682 mini_state: [0.4, 35.0, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.69822740314681
episode:  200 Evaluation Average Reward: -1.0803382303764641 avg distance 546.3803071948643 mini_state: [0.10000000000000007, 27.300000000000104, 7.89999999999998, 0.3] mini_distance: 543.7457922296397
episode:  300 Evaluation Average Reward: -6.833979271129686 avg distance 56.30776871624967 mini_state: [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3] mini_distance: 56.307768716249676
episode:  400 Evaluation Average Reward: 0.5555103027358925 avg distance 28.480325825489324 mini_state: [6.938893903907228e-17, 33.75000000000007, 1.850000000000001, 0.7000000000000001] mini_distance: 28.480325825489324
episode:  500 Evaluation Average Reward: -5.730953855906132 avg distance 57.81484490094833 mini_state: [0.4, 34.70000000000002, 0.2, 1.3877787807814457e-17] mini_distance: 57.81484490094833
episode:  600 Evaluation Average Reward: 0.6768437435519593 avg distance 28.33841316796724 mini_state: [6.938893903907228e-17, 33.95000000000006, 1.6500000000000008, 0.7000000000000001] mini_distance: 28.33841316796724
episode:  700 Evaluation Average Reward: -14.339966123676891 avg distance 56.29932765710858 mini_state: [0.4, 35.0, 1.3877787807814457e-17, 0.3] mini_distance: 56.29932765710857
episode:  800 Evaluation Average Reward: -11.848997471773616 avg distance 56.29932765710858 mini_state: [0.4, 35.0, 1.3877787807814457e-17, 0.3] mini_distance: 56.29932765710857
episode:  900 Evaluation Average Reward: -15.133327667531598 avg distance 56.29932765710858 mini_state: [0.4, 35.0, 1.3877787807814457e-17, 0.3] mini_distance: 56.29932765710857
episode:  1000 Evaluation Average Reward: -19.6658789159504 avg distance 56.29068360680999 mini_state: [0.4, 35.19999999999999, 1.3877787807814457e-17, 0.3] mini_distance: 56.290683606809985
episode:  1100 Evaluation Average Reward: -3.623170484088077 avg distance 57.796829848298316 mini_state: [6.938893903907228e-17, 35.19999999999999, 0.39999999999999997, 0.10000000000000002] mini_distance: 57.796829848298316
episode:  1200 Evaluation Average Reward: -0.015623958991534804 avg distance 57.81713972936935 mini_state: [0.30000000000000004, 35.249999999999986, 0.05000000000000002, 0.05000000000000002] mini_distance: 57.81713972936935
episode:  1300 Evaluation Average Reward: -8.29358880639967 avg distance 448.2637683340064 mini_state: [2.7999999999999985, 34.80000000000001, 1.4500000000000006, 1.3500000000000005] mini_distance: 356.351895743713
episode:  1400 Evaluation Average Reward: -12.268611780108614 avg distance 57.81484490094833 mini_state: [0.4, 35.0, 0.2, 1.3877787807814457e-17] mini_distance: 57.81484490094833
episode:  1500 Evaluation Average Reward: 0.25358493924552944 avg distance 52.50904064847488 mini_state: [2.4999999999999996, 29.500000000000135, 0.7999999999999998, 0.3] mini_distance: 52.50904064847488
episode:  1600 Evaluation Average Reward: 0.09386499733849528 avg distance 57.812062930958255 mini_state: [0.7000000000000002, 14.549999999999923, 0.2, 1.3877787807814457e-17] mini_distance: 57.812062930958255
episode:  1700 Evaluation Average Reward: -22.217386820781623 avg distance 461.6187997518641 mini_state: [0.4, 36.09999999999994, 0.2, 1.4000000000000006] mini_distance: 427.88095986744304
episode:  1800 Evaluation Average Reward: -0.0831792288553824 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  1900 Evaluation Average Reward: -11.306984478062581 avg distance 56.30776871624967 mini_state: [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3] mini_distance: 56.307768716249676
episode:  2000 Evaluation Average Reward: 0.05907479591437708 avg distance 56.60524710704355 mini_state: [0.7000000000000002, 25.65000000000008, 0.39999999999999997, 0.3] mini_distance: 56.605247107043546
episode:  2100 Evaluation Average Reward: -0.1374366679152858 avg distance 56.75082352377099 mini_state: [0.4, 24.30000000000006, 0.2, 0.3] mini_distance: 56.750823523771
episode:  2200 Evaluation Average Reward: 0.03734393345722534 avg distance 39.493943781353046 mini_state: [1.600000000000001, 39.999999999999716, 1.4000000000000006, 0.3] mini_distance: 39.49394378135305
episode:  2300 Evaluation Average Reward: -0.6538923643052613 avg distance 55.64145214624206 mini_state: [0.4, 49.99999999999915, 0.2, 0.3] mini_distance: 55.64145214624207
episode:  2400 Evaluation Average Reward: -0.25988259128330543 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  2500 Evaluation Average Reward: 0.19911297198637756 avg distance 56.202709517258214 mini_state: [0.4, 36.94999999999989, 0.2, 0.3] mini_distance: 56.20270951725822
episode:  2600 Evaluation Average Reward: -0.17659676226165763 avg distance 55.69074070913079 mini_state: [0.4, 48.84999999999921, 0.2, 0.3] mini_distance: 55.69074070913079
episode:  2700 Evaluation Average Reward: -1.4029781464968771 avg distance 56.24510822486785 mini_state: [6.938893903907228e-17, 36.04999999999994, 0.2, 0.3] mini_distance: 56.245108224867856
episode:  2800 Evaluation Average Reward: -1.1473561629478555 avg distance 542.3010766047951 mini_state: [0.4, 39.94999999999972, 5.14999999999999, 0.3] mini_distance: 509.7891184718877
episode:  2900 Evaluation Average Reward: -1.0160428908018504 avg distance 489.4150235144236 mini_state: [0.6500000000000001, 30.55000000000015, 4.399999999999992, 0.5499999999999999] mini_distance: 469.6935973738326
episode:  3000 Evaluation Average Reward: -0.26494090163020806 avg distance 56.60311159507252 mini_state: [0.4, 27.70000000000011, 0.2, 0.3] mini_distance: 56.60311159507251
episode:  3100 Evaluation Average Reward: -0.17714523931980478 avg distance 57.16507844060375 mini_state: [0.4, 14.799999999999926, 0.2, 0.3] mini_distance: 57.16507844060374
episode:  3200 Evaluation Average Reward: -3.080648455788901 avg distance 56.27319091687521 mini_state: [6.938893903907228e-17, 35.39999999999998, 0.6, 0.3] mini_distance: 56.2731909168752
episode:  3300 Evaluation Average Reward: -7.6210147411575475 avg distance 56.27319091687521 mini_state: [6.938893903907228e-17, 35.39999999999998, 0.6, 0.3] mini_distance: 56.2731909168752
episode:  3400 Evaluation Average Reward: 0.10123385190145387 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  3500 Evaluation Average Reward: 0.023768848974227458 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  3600 Evaluation Average Reward: -8.776239332568363 avg distance 57.812062930958255 mini_state: [0.7000000000000002, 35.0, 0.2, 1.3877787807814457e-17] mini_distance: 57.812062930958255
episode:  3700 Evaluation Average Reward: -5.761398877291578 avg distance 56.30776871624967 mini_state: [6.938893903907228e-17, 34.60000000000002, 0.2, 0.3] mini_distance: 56.307768716249676
episode:  3800 Evaluation Average Reward: -6.666533116053732 avg distance 56.30776871624967 mini_state: [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3] mini_distance: 56.307768716249676
episode:  3900 Evaluation Average Reward: -11.507830666188259 avg distance 56.30375407501657 mini_state: [0.6000000000000001, 35.0, 1.3877787807814457e-17, 0.3] mini_distance: 56.30375407501657
episode:  4000 Evaluation Average Reward: -8.53524468111455 avg distance 56.30375407501657 mini_state: [0.6000000000000001, 35.0, 1.3877787807814457e-17, 0.3] mini_distance: 56.30375407501657
episode:  4100 Evaluation Average Reward: -4.144282427418048 avg distance 57.608075865529045 mini_state: [0.7000000000000002, 35.0, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.60807586552904
episode:  4200 Evaluation Average Reward: -8.202534487416 avg distance 57.668167965925974 mini_state: [0.5, 35.29999999999998, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.668167965925974
episode:  4300 Evaluation Average Reward: -4.212371021526015 avg distance 452.6050848044394 mini_state: [2.899999999999998, 33.500000000000085, 2.0500000000000007, 1.2500000000000004] mini_distance: 343.4969808501933
episode:  4400 Evaluation Average Reward: 0.15338132027075854 avg distance 56.15307915651967 mini_state: [0.4, 38.099999999999824, 0.2, 0.3] mini_distance: 56.15307915651966
episode:  4500 Evaluation Average Reward: -11.898762637103955 avg distance 433.5215337404922 mini_state: [0.10000000000000007, 37.399999999999864, 1.2500000000000004, 1.3500000000000005] mini_distance: 332.87349894426524
episode:  4600 Evaluation Average Reward: -0.195722295402012 avg distance 20.784105357465204 mini_state: [0.4, 22.600000000000037, 1.3877787807814457e-17, 0.8500000000000002] mini_distance: 20.784105357465208
episode:  4700 Evaluation Average Reward: -12.810834636013736 avg distance 56.30797270645088 mini_state: [0.4, 34.80000000000001, 1.3877787807814457e-17, 0.3] mini_distance: 56.30797270645088
episode:  4800 Evaluation Average Reward: -1.7426163173386309 avg distance 57.491169083466914 mini_state: [6.938893903907228e-17, 35.39999999999998, 0.2, 0.2] mini_distance: 57.491169083466914
episode:  4900 Evaluation Average Reward: -8.373863090524837 avg distance 457.16036348976905 mini_state: [2.699999999999999, 32.70000000000013, 0.2, 1.4500000000000006] mini_distance: 456.97137508233766
episode:  5000 Evaluation Average Reward: -1.08262985219843 avg distance 56.32722575292435 mini_state: [6.938893903907228e-17, 34.15000000000005, 3.349999999999996, 0.3] mini_distance: 56.327225752924356
episode:  5100 Evaluation Average Reward: -13.496970659097773 avg distance 57.81484490094833 mini_state: [0.4, 35.0, 0.2, 1.3877787807814457e-17] mini_distance: 57.81484490094833
episode:  5200 Evaluation Average Reward: -4.837374634295474 avg distance 501.86546352753504 mini_state: [3.0499999999999976, 35.0, 2.549999999999999, 1.0500000000000003] mini_distance: 461.63617495824496
episode:  5300 Evaluation Average Reward: -1.0910064577457788 avg distance 57.769885842582234 mini_state: [5.24999999999999, 35.449999999999974, 0.2, 1.3877787807814457e-17] mini_distance: 57.769885842582234
episode:  5400 Evaluation Average Reward: -3.6571706828882315 avg distance 536.4053421808574 mini_state: [3.6999999999999953, 33.3000000000001, 2.6999999999999984, 0.3] mini_distance: 501.7944564814144
episode:  5500 Evaluation Average Reward: -0.9232189933723294 avg distance 501.16813592700316 mini_state: [10.600000000000017, 40.04999999999971, 1.900000000000001, 0.8000000000000002] mini_distance: 434.63112695120645
episode:  5600 Evaluation Average Reward: 0.09574338024729548 avg distance 26.67454404219395 mini_state: [1.650000000000001, 27.0000000000001, 0.7, 0.7500000000000001] mini_distance: 26.674544042193947
episode:  5700 Evaluation Average Reward: -1.2071144191689922 avg distance 57.14357249736766 mini_state: [2.2500000000000004, 37.44999999999986, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.14357249736765
episode:  5800 Evaluation Average Reward: -1.1675260021886882 avg distance 46.80079905300466 mini_state: [1.3000000000000007, 33.150000000000105, 1.3000000000000005, 0.049999999999999906] mini_distance: 46.80079905300466
episode:  5900 Evaluation Average Reward: -0.4052720067411235 avg distance 53.00261815349596 mini_state: [0.4, 49.99999999999915, 1.2000000000000004, 0.3] mini_distance: 53.00261815349596
episode:  6000 Evaluation Average Reward: -10.821686031696371 avg distance 56.29068360680999 mini_state: [0.4, 35.19999999999999, 1.3877787807814457e-17, 0.3] mini_distance: 56.290683606809985
episode:  6100 Evaluation Average Reward: -0.061993857104712106 avg distance 56.18760112820598 mini_state: [0.4, 37.29999999999987, 0.2, 0.3] mini_distance: 56.18760112820598
episode:  6200 Evaluation Average Reward: -0.06665025629984346 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  6300 Evaluation Average Reward: -8.313519408480914 avg distance 362.6988800850082 mini_state: [0.20000000000000007, 34.900000000000006, 2.8999999999999977, 1.3500000000000005] mini_distance: 337.06992078963873
episode:  6400 Evaluation Average Reward: 0.07051180581561868 avg distance 56.36831832834007 mini_state: [6.938893903907228e-17, 33.2000000000001, 2.000000000000001, 0.3] mini_distance: 56.36831832834006
episode:  6500 Evaluation Average Reward: -2.1019969217195515 avg distance 505.04638334066647 mini_state: [2.4, 34.15000000000005, 3.049999999999997, 0.3] mini_distance: 497.57132074753196
episode:  6600 Evaluation Average Reward: -0.9376210492637072 avg distance 44.25685942636727 mini_state: [0.05000000000000007, 35.69999999999996, 3.8499999999999943, 1.3877787807814457e-17] mini_distance: 44.25685942636727
episode:  6700 Evaluation Average Reward: 0.15588506442029837 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  6800 Evaluation Average Reward: -0.9187740148510338 avg distance 43.76665331388133 mini_state: [0.30000000000000004, 34.050000000000054, 2.2, 1.3877787807814457e-17] mini_distance: 43.766653313881335
episode:  6900 Evaluation Average Reward: 0.051671361652063916 avg distance 42.6765109229231 mini_state: [0.6000000000000001, 49.99999999999915, 3.4499999999999957, 0.3] mini_distance: 42.67651092292309
episode:  7000 Evaluation Average Reward: -1.0332417912604162 avg distance 473.58499644510067 mini_state: [0.05000000000000007, 41.89999999999961, 1.3000000000000005, 1.3000000000000005] mini_distance: 313.66547259078004
episode:  7100 Evaluation Average Reward: -3.012279137240543 avg distance 56.37805895477747 mini_state: [2.100000000000001, 34.050000000000054, 1.3877787807814457e-17, 0.3] mini_distance: 56.37805895477747
episode:  7200 Evaluation Average Reward: -18.312244674766756 avg distance 56.295109974729385 mini_state: [0.6000000000000001, 35.19999999999999, 1.3877787807814457e-17, 0.3] mini_distance: 56.295109974729385
episode:  7300 Evaluation Average Reward: -3.2762406188133992 avg distance 547.1633005718317 mini_state: [2.949999999999998, 36.54999999999991, 2.849999999999998, 0.3] mini_distance: 459.27774878040117
episode:  7400 Evaluation Average Reward: -0.11932276487472615 avg distance 51.849536647341225 mini_state: [0.6500000000000001, 23.750000000000053, 1.2500000000000004, 0.3] mini_distance: 51.849536647341225
episode:  7500 Evaluation Average Reward: -9.77138832447278 avg distance 57.79693071375807 mini_state: [0.20000000000000007, 35.19999999999999, 1.3877787807814457e-17, 0.10000000000000002] mini_distance: 57.79693071375807
episode:  7600 Evaluation Average Reward: -1.6605877903994801 avg distance 39.59980374752762 mini_state: [6.938893903907228e-17, 34.15000000000005, 1.0500000000000003, 0.6] mini_distance: 39.59980374752762
episode:  7700 Evaluation Average Reward: -6.368317533294609 avg distance 56.30776871624967 mini_state: [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3] mini_distance: 56.307768716249676
episode:  7800 Evaluation Average Reward: 0.02180200939963486 avg distance 37.44756570380793 mini_state: [1.3000000000000007, 31.20000000000016, 1.3500000000000005, 0.49999999999999994] mini_distance: 37.44756570380794
episode:  7900 Evaluation Average Reward: -0.009316995607799135 avg distance 28.159491681370987 mini_state: [4.249999999999994, 34.200000000000045, 0.25, 0.7000000000000001] mini_distance: 28.159491681370984
episode:  8000 Evaluation Average Reward: -0.09723521272147893 avg distance 175.01404128935675 mini_state: [13.100000000000053, 49.99999999999915, 1.7000000000000008, 0.3] mini_distance: 175.01404128935673
episode:  8100 Evaluation Average Reward: -3.663992333637407 avg distance 545.7829409473152 mini_state: [4.549999999999993, 29.15000000000013, 2.25, 1.1500000000000004] mini_distance: 501.36372118911453
episode:  8200 Evaluation Average Reward: 0.24173428817387282 avg distance 57.611092076556375 mini_state: [0.5, 35.0, 0.44999999999999996, 0.15000000000000002] mini_distance: 57.61109207655638
episode:  8300 Evaluation Average Reward: -13.167366434482933 avg distance 463.6676430841618 mini_state: [0.9000000000000004, 33.90000000000006, 0.25, 1.4000000000000006] mini_distance: 360.2997562438152
episode:  8400 Evaluation Average Reward: 0.08984362478841704 avg distance 28.77299592603574 mini_state: [0.5, 35.249999999999986, 1.4500000000000006, 0.65] mini_distance: 28.772995926035744
episode:  8500 Evaluation Average Reward: -13.261972808559387 avg distance 56.295109974729385 mini_state: [0.6000000000000001, 35.19999999999999, 1.3877787807814457e-17, 0.3] mini_distance: 56.295109974729385
episode:  8600 Evaluation Average Reward: -0.04056914222226188 avg distance 50.89482589396097 mini_state: [0.8000000000000003, 24.20000000000006, 1.3000000000000003, 0.049999999999999906] mini_distance: 50.89482589396098
episode:  8700 Evaluation Average Reward: -0.6643192433928017 avg distance 524.4413254570418 mini_state: [0.7000000000000002, 36.09999999999994, 4.299999999999993, 0.35] mini_distance: 451.276948432593
episode:  8800 Evaluation Average Reward: -0.84329206909515 avg distance 501.4655419855636 mini_state: [4.299999999999994, 28.950000000000127, 2.549999999999999, 0.3] mini_distance: 439.72221201223863
episode:  8900 Evaluation Average Reward: -1.2527889161299688 avg distance 492.29233808795004 mini_state: [0.45, 35.34999999999998, 4.94999999999999, 0.35] mini_distance: 492.29233808795
episode:  9000 Evaluation Average Reward: -0.6542597873893197 avg distance 321.8481504659402 mini_state: [0.30000000000000004, 37.29999999999987, 5.299999999999989, 1.3877787807814457e-17] mini_distance: 321.84815046594014
episode:  9100 Evaluation Average Reward: -0.79010758697178 avg distance 544.9236652736165 mini_state: [0.4, 32.40000000000015, 4.99999999999999, 0.8500000000000002] mini_distance: 506.1239277786823
episode:  9200 Evaluation Average Reward: -0.7057397056376171 avg distance 542.1222289569256 mini_state: [0.4, 35.89999999999995, 5.14999999999999, 0.3] mini_distance: 509.61783993568883
episode:  9300 Evaluation Average Reward: -0.2503523567399316 avg distance 55.64145214624206 mini_state: [0.4, 49.99999999999915, 0.2, 0.3] mini_distance: 55.64145214624207
episode:  9400 Evaluation Average Reward: -0.16899211818743803 avg distance 55.64145214624206 mini_state: [0.4, 49.99999999999915, 0.2, 0.3] mini_distance: 55.64145214624207
episode:  9500 Evaluation Average Reward: -0.27876565174979956 avg distance 55.47258774985163 mini_state: [0.30000000000000004, 49.99999999999915, 0.6, 0.3] mini_distance: 55.472587749851634
episode:  9600 Evaluation Average Reward: -0.46650684328038516 avg distance 53.46927407883386 mini_state: [0.20000000000000007, 49.99999999999915, 1.6500000000000008, 0.2] mini_distance: 53.469274078833855
episode:  9700 Evaluation Average Reward: -2.888164398264916 avg distance 335.25159316251194 mini_state: [0.05000000000000007, 40.79999999999967, 5.4999999999999885, 1.2500000000000004] mini_distance: 308.5774636839302
episode:  9800 Evaluation Average Reward: -0.9361420058297467 avg distance 301.32620629307087 mini_state: [0.15000000000000008, 40.49999999999969, 6.199999999999986, 0.8500000000000002] mini_distance: 301.3262062930709
episode:  9900 Evaluation Average Reward: -0.006211652088257058 avg distance 28.740108258802934 mini_state: [0.05000000000000007, 39.19999999999976, 6.499999999999985, 0.8000000000000002] mini_distance: 28.740108258802934
episode:  10000 Evaluation Average Reward: 0.40488860375671687 avg distance 12.973713593822087 mini_state: [0.7000000000000002, 36.999999999999886, 1.3877787807814457e-17, 0.8000000000000002] mini_distance: 12.97371359382209
episode:  10100 Evaluation Average Reward: -0.5240522602472747 avg distance 56.006170150606906 mini_state: [0.7000000000000002, 41.949999999999605, 1.3877787807814457e-17, 0.3] mini_distance: 56.006170150606906
episode:  10200 Evaluation Average Reward: -4.195932933646241 avg distance 57.08592837342063 mini_state: [1.2500000000000007, 35.14999999999999, 0.6, 1.3877787807814457e-17] mini_distance: 57.08592837342062
episode:  10300 Evaluation Average Reward: -0.08788754790479157 avg distance 17.931682281284484 mini_state: [5.549999999999989, 49.99999999999915, 1.3000000000000005, 0.3] mini_distance: 17.931682281284484
episode:  10400 Evaluation Average Reward: 0.1518652894769445 avg distance 56.40932485312875 mini_state: [2.699999999999999, 31.700000000000166, 0.2, 0.3] mini_distance: 56.40932485312875
episode:  10500 Evaluation Average Reward: 0.08448609526737166 avg distance 43.16088387391373 mini_state: [2.7999999999999985, 35.99999999999994, 1.1000000000000003, 0.3] mini_distance: 43.160883873913725
episode:  10600 Evaluation Average Reward: 0.237526572813634 avg distance 56.467932750543596 mini_state: [2.2500000000000004, 32.05000000000017, 1.3877787807814457e-17, 0.3] mini_distance: 56.4679327505436
episode:  10700 Evaluation Average Reward: -25.117833739051306 avg distance 441.9582114173833 mini_state: [1.5000000000000009, 33.90000000000006, 1.3000000000000005, 1.4000000000000006] mini_distance: 395.26259076694237
episode:  10800 Evaluation Average Reward: -3.146555083143714 avg distance 55.26556421589345 mini_state: [0.8500000000000003, 34.25000000000004, 0.9500000000000003, 1.3877787807814457e-17] mini_distance: 55.26556421589345
episode:  10900 Evaluation Average Reward: -2.4048959829515937 avg distance 57.608075865529045 mini_state: [0.7000000000000002, 34.70000000000002, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.60807586552904
a1,a2,r1,r2:[6.938893903907228e-17, 35.05, 2.3499999999999996, 0.9500000000000003]

episode:  11000 Evaluation Average Reward: 1.0692917554633214 avg distance 0.36874684260820045 mini_state: [6.938893903907228e-17, 35.05, 2.3499999999999996, 0.9500000000000003] mini_distance: 0.36874684260820045
[[0.4, 36.09999999999994, 1.3000000000000005, 1.4000000000000006], [0.4, 35.0, 0.49999999999999994, 1.3877787807814457e-17], [0.10000000000000007, 27.300000000000104, 7.89999999999998, 0.3], [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3], [6.938893903907228e-17, 33.75000000000007, 1.850000000000001, 0.7000000000000001], [0.4, 34.70000000000002, 0.2, 1.3877787807814457e-17], [6.938893903907228e-17, 33.95000000000006, 1.6500000000000008, 0.7000000000000001], [0.4, 35.0, 1.3877787807814457e-17, 0.3], [0.4, 35.0, 1.3877787807814457e-17, 0.3], [0.4, 35.0, 1.3877787807814457e-17, 0.3], [0.4, 35.19999999999999, 1.3877787807814457e-17, 0.3], [6.938893903907228e-17, 35.19999999999999, 0.39999999999999997, 0.10000000000000002], [0.30000000000000004, 35.249999999999986, 0.05000000000000002, 0.05000000000000002], [2.7999999999999985, 34.80000000000001, 1.4500000000000006, 1.3500000000000005], [0.4, 35.0, 0.2, 1.3877787807814457e-17], [2.4999999999999996, 29.500000000000135, 0.7999999999999998, 0.3], [0.7000000000000002, 14.549999999999923, 0.2, 1.3877787807814457e-17], [0.4, 36.09999999999994, 0.2, 1.4000000000000006], [0.4, 35.0, 0.2, 0.3], [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3], [0.7000000000000002, 25.65000000000008, 0.39999999999999997, 0.3], [0.4, 24.30000000000006, 0.2, 0.3], [1.600000000000001, 39.999999999999716, 1.4000000000000006, 0.3], [0.4, 49.99999999999915, 0.2, 0.3], [0.4, 35.0, 0.2, 0.3], [0.4, 36.94999999999989, 0.2, 0.3], [0.4, 48.84999999999921, 0.2, 0.3], [6.938893903907228e-17, 36.04999999999994, 0.2, 0.3], [0.4, 39.94999999999972, 5.14999999999999, 0.3], [0.6500000000000001, 30.55000000000015, 4.399999999999992, 0.5499999999999999], [0.4, 27.70000000000011, 0.2, 0.3], [0.4, 14.799999999999926, 0.2, 0.3], [6.938893903907228e-17, 35.39999999999998, 0.6, 0.3], [6.938893903907228e-17, 35.39999999999998, 0.6, 0.3], [0.4, 35.0, 0.2, 0.3], [0.4, 35.0, 0.2, 0.3], [0.7000000000000002, 35.0, 0.2, 1.3877787807814457e-17], [6.938893903907228e-17, 34.60000000000002, 0.2, 0.3], [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3], [0.6000000000000001, 35.0, 1.3877787807814457e-17, 0.3], [0.6000000000000001, 35.0, 1.3877787807814457e-17, 0.3], [0.7000000000000002, 35.0, 0.49999999999999994, 1.3877787807814457e-17], [0.5, 35.29999999999998, 0.49999999999999994, 1.3877787807814457e-17], [2.899999999999998, 33.500000000000085, 2.0500000000000007, 1.2500000000000004], [0.4, 38.099999999999824, 0.2, 0.3], [0.10000000000000007, 37.399999999999864, 1.2500000000000004, 1.3500000000000005], [0.4, 22.600000000000037, 1.3877787807814457e-17, 0.8500000000000002], [0.4, 34.80000000000001, 1.3877787807814457e-17, 0.3], [6.938893903907228e-17, 35.39999999999998, 0.2, 0.2], [2.699999999999999, 32.70000000000013, 0.2, 1.4500000000000006], [6.938893903907228e-17, 34.15000000000005, 3.349999999999996, 0.3], [0.4, 35.0, 0.2, 1.3877787807814457e-17], [3.0499999999999976, 35.0, 2.549999999999999, 1.0500000000000003], [5.24999999999999, 35.449999999999974, 0.2, 1.3877787807814457e-17], [3.6999999999999953, 33.3000000000001, 2.6999999999999984, 0.3], [10.600000000000017, 40.04999999999971, 1.900000000000001, 0.8000000000000002], [1.650000000000001, 27.0000000000001, 0.7, 0.7500000000000001], [2.2500000000000004, 37.44999999999986, 0.49999999999999994, 1.3877787807814457e-17], [1.3000000000000007, 33.150000000000105, 1.3000000000000005, 0.049999999999999906], [0.4, 49.99999999999915, 1.2000000000000004, 0.3], [0.4, 35.19999999999999, 1.3877787807814457e-17, 0.3], [0.4, 37.29999999999987, 0.2, 0.3], [0.4, 35.0, 0.2, 0.3], [0.20000000000000007, 34.900000000000006, 2.8999999999999977, 1.3500000000000005], [6.938893903907228e-17, 33.2000000000001, 2.000000000000001, 0.3], [2.4, 34.15000000000005, 3.049999999999997, 0.3], [0.05000000000000007, 35.69999999999996, 3.8499999999999943, 1.3877787807814457e-17], [0.4, 35.0, 0.2, 0.3], [0.30000000000000004, 34.050000000000054, 2.2, 1.3877787807814457e-17], [0.6000000000000001, 49.99999999999915, 3.4499999999999957, 0.3], [0.05000000000000007, 41.89999999999961, 1.3000000000000005, 1.3000000000000005], [2.100000000000001, 34.050000000000054, 1.3877787807814457e-17, 0.3], [0.6000000000000001, 35.19999999999999, 1.3877787807814457e-17, 0.3], [2.949999999999998, 36.54999999999991, 2.849999999999998, 0.3], [0.6500000000000001, 23.750000000000053, 1.2500000000000004, 0.3], [0.20000000000000007, 35.19999999999999, 1.3877787807814457e-17, 0.10000000000000002], [6.938893903907228e-17, 34.15000000000005, 1.0500000000000003, 0.6], [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3], [1.3000000000000007, 31.20000000000016, 1.3500000000000005, 0.49999999999999994], [4.249999999999994, 34.200000000000045, 0.25, 0.7000000000000001], [13.100000000000053, 49.99999999999915, 1.7000000000000008, 0.3], [4.549999999999993, 29.15000000000013, 2.25, 1.1500000000000004], [0.5, 35.0, 0.44999999999999996, 0.15000000000000002], [0.9000000000000004, 33.90000000000006, 0.25, 1.4000000000000006], [0.5, 35.249999999999986, 1.4500000000000006, 0.65], [0.6000000000000001, 35.19999999999999, 1.3877787807814457e-17, 0.3], [0.8000000000000003, 24.20000000000006, 1.3000000000000003, 0.049999999999999906], [0.7000000000000002, 36.09999999999994, 4.299999999999993, 0.35], [4.299999999999994, 28.950000000000127, 2.549999999999999, 0.3], [0.45, 35.34999999999998, 4.94999999999999, 0.35], [0.30000000000000004, 37.29999999999987, 5.299999999999989, 1.3877787807814457e-17], [0.4, 32.40000000000015, 4.99999999999999, 0.8500000000000002], [0.4, 35.89999999999995, 5.14999999999999, 0.3], [0.4, 49.99999999999915, 0.2, 0.3], [0.4, 49.99999999999915, 0.2, 0.3], [0.30000000000000004, 49.99999999999915, 0.6, 0.3], [0.20000000000000007, 49.99999999999915, 1.6500000000000008, 0.2], [0.05000000000000007, 40.79999999999967, 5.4999999999999885, 1.2500000000000004], [0.15000000000000008, 40.49999999999969, 6.199999999999986, 0.8500000000000002], [0.05000000000000007, 39.19999999999976, 6.499999999999985, 0.8000000000000002], [0.7000000000000002, 36.999999999999886, 1.3877787807814457e-17, 0.8000000000000002], [0.7000000000000002, 41.949999999999605, 1.3877787807814457e-17, 0.3], [1.2500000000000007, 35.14999999999999, 0.6, 1.3877787807814457e-17], [5.549999999999989, 49.99999999999915, 1.3000000000000005, 0.3], [2.699999999999999, 31.700000000000166, 0.2, 0.3], [2.7999999999999985, 35.99999999999994, 1.1000000000000003, 0.3], [2.2500000000000004, 32.05000000000017, 1.3877787807814457e-17, 0.3], [1.5000000000000009, 33.90000000000006, 1.3000000000000005, 1.4000000000000006], [0.8500000000000003, 34.25000000000004, 0.9500000000000003, 1.3877787807814457e-17], [0.7000000000000002, 34.70000000000002, 0.49999999999999994, 1.3877787807814457e-17], [6.938893903907228e-17, 35.05, 2.3499999999999996, 0.9500000000000003]]
[438.028433985708, 57.69822740314681, 543.7457922296397, 56.307768716249676, 28.480325825489324, 57.81484490094833, 28.33841316796724, 56.29932765710857, 56.29932765710857, 56.29932765710857, 56.290683606809985, 57.796829848298316, 57.81713972936935, 356.351895743713, 57.81484490094833, 52.50904064847488, 57.812062930958255, 427.88095986744304, 56.28694083658173, 56.307768716249676, 56.605247107043546, 56.750823523771, 39.49394378135305, 55.64145214624207, 56.28694083658173, 56.20270951725822, 55.69074070913079, 56.245108224867856, 509.7891184718877, 469.6935973738326, 56.60311159507251, 57.16507844060374, 56.2731909168752, 56.2731909168752, 56.28694083658173, 56.28694083658173, 57.812062930958255, 56.307768716249676, 56.307768716249676, 56.30375407501657, 56.30375407501657, 57.60807586552904, 57.668167965925974, 343.4969808501933, 56.15307915651966, 332.87349894426524, 20.784105357465208, 56.30797270645088, 57.491169083466914, 456.97137508233766, 56.327225752924356, 57.81484490094833, 461.63617495824496, 57.769885842582234, 501.7944564814144, 434.63112695120645, 26.674544042193947, 57.14357249736765, 46.80079905300466, 53.00261815349596, 56.290683606809985, 56.18760112820598, 56.28694083658173, 337.06992078963873, 56.36831832834006, 497.57132074753196, 44.25685942636727, 56.28694083658173, 43.766653313881335, 42.67651092292309, 313.66547259078004, 56.37805895477747, 56.295109974729385, 459.27774878040117, 51.849536647341225, 57.79693071375807, 39.59980374752762, 56.307768716249676, 37.44756570380794, 28.159491681370984, 175.01404128935673, 501.36372118911453, 57.61109207655638, 360.2997562438152, 28.772995926035744, 56.295109974729385, 50.89482589396098, 451.276948432593, 439.72221201223863, 492.29233808795, 321.84815046594014, 506.1239277786823, 509.61783993568883, 55.64145214624207, 55.64145214624207, 55.472587749851634, 53.469274078833855, 308.5774636839302, 301.3262062930709, 28.740108258802934, 12.97371359382209, 56.006170150606906, 57.08592837342062, 17.931682281284484, 56.40932485312875, 43.160883873913725, 56.4679327505436, 395.26259076694237, 55.26556421589345, 57.60807586552904, 0.36874684260820045]

Process finished with exit code 0

