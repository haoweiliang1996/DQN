/usr/bin/python3.5 /home/haowei/PycharmProjects/DQN/four.py
fig size: 80.0 DPI, size in inches [ 3.  4.]
env init ok
episode:20000,stepTimes:1200,stepSize:0.05,gbest: False,Ok_eps:1.0,init_state: [0.4, 35, 0.2, 0.3],agent_saved:True range: [50, 100]
episode:  0 Evaluation Average Reward: -21.12525341443743 avg distance 56.30797270645088 mini_state: [0.4, 34.80000000000001, 1.3877787807814457e-17, 0.3] mini_distance: 56.30797270645088
/home/haowei/.local/lib/python3.5/site-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented
  warnings.warn(str, mplDeprecation)
episode:  100 Evaluation Average Reward: -19.725270720253462 avg distance 56.30797270645088 mini_state: [0.4, 34.80000000000001, 1.3877787807814457e-17, 0.3] mini_distance: 56.30797270645088
episode:  200 Evaluation Average Reward: -5.768492593876453 avg distance 57.812062930958255 mini_state: [0.7000000000000002, 34.70000000000002, 0.2, 1.3877787807814457e-17] mini_distance: 57.812062930958255
episode:  300 Evaluation Average Reward: -12.024558712433825 avg distance 57.608075865529045 mini_state: [0.7000000000000002, 35.0, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.60807586552904
episode:  400 Evaluation Average Reward: -6.466798398805899 avg distance 57.608075865529045 mini_state: [0.7000000000000002, 35.0, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.60807586552904
episode:  500 Evaluation Average Reward: 0.009558818194982097 avg distance 53.73870380247611 mini_state: [0.4, 94.99999999999659, 0.2, 0.3] mini_distance: 53.73870380247611
episode:  600 Evaluation Average Reward: 0.09345896219019388 avg distance 53.73870380247611 mini_state: [0.4, 94.99999999999659, 0.2, 0.3] mini_distance: 53.73870380247611
episode:  700 Evaluation Average Reward: -0.14049609932632615 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  800 Evaluation Average Reward: 0.0954809341841291 avg distance 50.49226972546479 mini_state: [1.8500000000000012, 36.7499999999999, 0.35, 0.44999999999999996] mini_distance: 50.492269725464794
episode:  900 Evaluation Average Reward: -1.6616507672273941 avg distance 459.5596466890614 mini_state: [0.4, 49.499999999999176, 1.1500000000000004, 1.2500000000000004] mini_distance: 343.7038341948021
episode:  1000 Evaluation Average Reward: -0.21902587083700484 avg distance 57.69822740314682 mini_state: [0.4, 21.50000000000002, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.69822740314681
episode:  1100 Evaluation Average Reward: -10.646741789457815 avg distance 57.73717099110682 mini_state: [0.4, 35.249999999999986, 0.44999999999999996, 1.3877787807814457e-17] mini_distance: 57.73717099110682
episode:  1200 Evaluation Average Reward: 0.04380628375094337 avg distance 57.215891247231426 mini_state: [4.299999999999994, 67.04999999999818, 0.39999999999999997, 0.10000000000000002] mini_distance: 57.21589124723142
episode:  1300 Evaluation Average Reward: -0.05784239803523838 avg distance 54.858213474532405 mini_state: [5.19999999999999, 67.39999999999816, 0.2, 0.3] mini_distance: 54.858213474532405
episode:  1400 Evaluation Average Reward: -2.66745926406367 avg distance 33.891963060900665 mini_state: [6.938893903907228e-17, 34.70000000000002, 0.49999999999999994, 0.65] mini_distance: 33.89196306090067
episode:  1500 Evaluation Average Reward: -3.6610519190300956 avg distance 27.879796263756155 mini_state: [6.938893903907228e-17, 34.60000000000002, 0.6, 0.7000000000000001] mini_distance: 27.879796263756155
episode:  1600 Evaluation Average Reward: -0.11941471071164128 avg distance 54.81049318561814 mini_state: [6.799999999999985, 68.19999999999811, 0.2, 0.3] mini_distance: 54.810493185618135
episode:  1700 Evaluation Average Reward: 0.26761958485242 avg distance 54.709203083042226 mini_state: [10.200000000000012, 69.89999999999802, 0.2, 0.3] mini_distance: 54.70920308304224
episode:  1800 Evaluation Average Reward: -0.2613251257988874 avg distance 56.99177430702014 mini_state: [6.938893903907228e-17, 18.849999999999984, 2.6999999999999984, 0.3] mini_distance: 56.99177430702014
episode:  1900 Evaluation Average Reward: -4.066250740772645 avg distance 55.087167755763474 mini_state: [1.1000000000000005, 35.0, 0.9000000000000002, 1.3877787807814457e-17] mini_distance: 55.087167755763474
episode:  2000 Evaluation Average Reward: -4.502953487810373 avg distance 57.26923747073751 mini_state: [0.7000000000000002, 35.14999999999999, 0.65, 1.3877787807814457e-17] mini_distance: 57.26923747073752
episode:  2100 Evaluation Average Reward: -9.020656615378192 avg distance 47.82526402720589 mini_state: [0.6000000000000001, 35.19999999999999, 1.3877787807814457e-17, 0.49999999999999994] mini_distance: 47.82526402720589
episode:  2200 Evaluation Average Reward: -7.951779233541021 avg distance 57.498827750431005 mini_state: [0.20000000000000007, 34.70000000000002, 1.3877787807814457e-17, 0.2] mini_distance: 57.498827750431
episode:  2300 Evaluation Average Reward: -8.006346549233209 avg distance 56.30776871624967 mini_state: [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3] mini_distance: 56.307768716249676
episode:  2400 Evaluation Average Reward: -6.8884942424668285 avg distance 57.49393584177657 mini_state: [6.938893903907228e-17, 35.099999999999994, 0.3, 0.2] mini_distance: 57.49393584177657
episode:  2500 Evaluation Average Reward: -4.680526789960851 avg distance 47.79265075319439 mini_state: [0.20000000000000007, 35.19999999999999, 1.3877787807814457e-17, 0.49999999999999994] mini_distance: 47.792650753194394
episode:  2600 Evaluation Average Reward: -7.782507137627643 avg distance 57.81484490094833 mini_state: [0.4, 35.29999999999998, 0.2, 1.3877787807814457e-17] mini_distance: 57.81484490094833
episode:  2700 Evaluation Average Reward: -11.137437196615194 avg distance 56.30259533972311 mini_state: [0.45, 34.95, 1.3877787807814457e-17, 0.3] mini_distance: 56.302595339723105
episode:  2800 Evaluation Average Reward: -10.445587317069219 avg distance 56.312399174347206 mini_state: [0.6000000000000001, 34.80000000000001, 1.3877787807814457e-17, 0.3] mini_distance: 56.312399174347206
episode:  2900 Evaluation Average Reward: -3.83977374750316 avg distance 57.79003712196946 mini_state: [1.3000000000000007, 34.400000000000034, 0.25, 1.3877787807814457e-17] mini_distance: 57.79003712196946
episode:  3000 Evaluation Average Reward: -1.1943945522906403 avg distance 57.72829576504874 mini_state: [0.30000000000000004, 36.7499999999999, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.72829576504873
episode:  3100 Evaluation Average Reward: -13.966463871718611 avg distance 57.788459262897945 mini_state: [0.10000000000000007, 34.70000000000002, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.788459262897945
episode:  3200 Evaluation Average Reward: -7.762842312170853 avg distance 57.69822740314682 mini_state: [0.4, 34.70000000000002, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.69822740314681
episode:  3300 Evaluation Average Reward: -3.5562350014532464 avg distance 57.714037962333954 mini_state: [6.938893903907228e-17, 34.550000000000026, 0.35, 0.15000000000000002] mini_distance: 57.714037962333954
episode:  3400 Evaluation Average Reward: -5.11646266984528 avg distance 511.8276408151273 mini_state: [0.4, 27.900000000000112, 2.2, 1.4500000000000006] mini_distance: 350.2655532312241
episode:  3500 Evaluation Average Reward: -1.0049136944153088 avg distance 509.3292924575013 mini_state: [0.10000000000000007, 11.59999999999988, 1.5500000000000007, 1.950000000000001] mini_distance: 486.08811967854444
episode:  3600 Evaluation Average Reward: -4.747672821860029 avg distance 39.19390741215944 mini_state: [6.938893903907228e-17, 35.0, 0.3, 0.6] mini_distance: 39.19390741215944
episode:  3700 Evaluation Average Reward: -0.08847269753761308 avg distance 56.78048383337779 mini_state: [6.938893903907228e-17, 23.700000000000053, 1.0000000000000002, 0.3] mini_distance: 56.78048383337779
episode:  3800 Evaluation Average Reward: -1.5980567946398105 avg distance 43.822615864174786 mini_state: [6.938893903907228e-17, 35.249999999999986, 1.1500000000000004, 0.5499999999999999] mini_distance: 43.82261586417478
episode:  3900 Evaluation Average Reward: -0.2148216407889151 avg distance 56.27854144892895 mini_state: [1.3500000000000008, 35.0, 0.2, 0.3] mini_distance: 56.27854144892895
episode:  4000 Evaluation Average Reward: -0.44429501987056036 avg distance 48.11994610975035 mini_state: [3.499999999999996, 35.0, 1.3877787807814457e-17, 0.49999999999999994] mini_distance: 48.11994610975035
episode:  4100 Evaluation Average Reward: 0.0438760558605371 avg distance 56.50256667765511 mini_state: [6.938893903907228e-17, 30.100000000000144, 0.2, 0.3] mini_distance: 56.5025666776551
episode:  4200 Evaluation Average Reward: -0.3094921141984257 avg distance 57.037594968889735 mini_state: [6.938893903907228e-17, 17.79999999999997, 0.2, 0.3] mini_distance: 57.037594968889735
episode:  4300 Evaluation Average Reward: -0.01570038667775282 avg distance 21.481175576557266 mini_state: [1.550000000000001, 8.449999999999836, 0.8000000000000002, 1.1000000000000003] mini_distance: 21.48117557655727
episode:  4400 Evaluation Average Reward: 0.05950365828584477 avg distance 12.97231085412798 mini_state: [8.799999999999992, 35.0, 1.2000000000000004, 0.3] mini_distance: 12.97231085412798
episode:  4500 Evaluation Average Reward: -0.7415656250156774 avg distance 521.786099040776 mini_state: [5.699999999999989, 48.49999999999923, 2.3499999999999996, 0.6] mini_distance: 483.42941503602844
episode:  4600 Evaluation Average Reward: -0.8218777274154654 avg distance 56.1676818466227 mini_state: [7.099999999999984, 41.49999999999963, 1.3877787807814457e-17, 0.3] mini_distance: 56.16768184662269
episode:  4700 Evaluation Average Reward: -7.365811956082481 avg distance 56.30776871624967 mini_state: [6.938893903907228e-17, 34.60000000000002, 0.2, 0.3] mini_distance: 56.307768716249676
episode:  4800 Evaluation Average Reward: -7.967984555862973 avg distance 56.303547237615376 mini_state: [0.20000000000000007, 34.80000000000001, 1.3877787807814457e-17, 0.3] mini_distance: 56.30354723761538
episode:  4900 Evaluation Average Reward: -4.452563071874629 avg distance 56.28515205183983 mini_state: [0.15000000000000008, 35.19999999999999, 1.3877787807814457e-17, 0.3] mini_distance: 56.28515205183982
episode:  5000 Evaluation Average Reward: -6.800485869073322 avg distance 56.29047781847488 mini_state: [6.938893903907228e-17, 35.0, 0.2, 0.3] mini_distance: 56.29047781847488
episode:  5100 Evaluation Average Reward: -7.434486298818221 avg distance 47.933178580575394 mini_state: [0.6000000000000001, 34.80000000000001, 1.3877787807814457e-17, 0.49999999999999994] mini_distance: 47.9331785805754
episode:  5200 Evaluation Average Reward: -21.879259476549898 avg distance 486.4318836836172 mini_state: [0.4, 35.0, 0.2, 1.4000000000000006] mini_distance: 393.41817832255845
episode:  5300 Evaluation Average Reward: -18.24065366490836 avg distance 493.67694578379803 mini_state: [0.4, 36.04999999999994, 1.2500000000000004, 1.3500000000000005] mini_distance: 305.5934406696345
episode:  5400 Evaluation Average Reward: 0.07598122752450184 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  5500 Evaluation Average Reward: -0.1151045678148028 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  5600 Evaluation Average Reward: -0.046391675821526195 avg distance 56.286940836581735 mini_state: [0.4, 35.0, 0.2, 0.3] mini_distance: 56.28694083658173
episode:  5700 Evaluation Average Reward: -9.188084385260801 avg distance 57.69822740314682 mini_state: [0.4, 35.0, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.69822740314681
episode:  5800 Evaluation Average Reward: -0.25166444489046436 avg distance 57.53324470141207 mini_state: [0.4, 6.399999999999836, 0.2, 0.3] mini_distance: 57.533244701412066
episode:  5900 Evaluation Average Reward: 0.20357738373820874 avg distance 57.605511696874984 mini_state: [0.45, 8.099999999999831, 0.35, 0.25] mini_distance: 57.60551169687499
episode:  6000 Evaluation Average Reward: -5.016465442785978 avg distance 57.15749785778725 mini_state: [0.4, 34.400000000000034, 0.8000000000000002, 1.3877787807814457e-17] mini_distance: 57.15749785778725
episode:  6100 Evaluation Average Reward: -0.273429495697997 avg distance 41.052942869110964 mini_state: [6.938893903907228e-17, 42.94999999999955, 4.3499999999999925, 0.5499999999999999] mini_distance: 41.05294286911097
episode:  6200 Evaluation Average Reward: -11.63712247225009 avg distance 56.30797270645088 mini_state: [0.4, 34.80000000000001, 1.3877787807814457e-17, 0.3] mini_distance: 56.30797270645088
episode:  6300 Evaluation Average Reward: -1.7263673862723805 avg distance 489.53045840324364 mini_state: [1.650000000000001, 23.000000000000043, 0.5499999999999998, 1.6000000000000008] mini_distance: 457.5715208780375
episode:  6400 Evaluation Average Reward: 1.0325872959747668 avg distance 56.55242951998976 mini_state: [6.938893903907228e-17, 28.950000000000127, 1.2000000000000004, 0.3] mini_distance: 56.55242951998976
episode:  6500 Evaluation Average Reward: -0.2491151857377491 avg distance 56.74351404877102 mini_state: [6.938893903907228e-17, 24.550000000000065, 2.9499999999999975, 0.3] mini_distance: 56.74351404877101
episode:  6600 Evaluation Average Reward: -2.9922626256563074 avg distance 501.34992023690495 mini_state: [2.150000000000001, 33.2500000000001, 3.149999999999997, 0.3] mini_distance: 501.3499202369049
episode:  6700 Evaluation Average Reward: -11.150080167964827 avg distance 56.303547237615376 mini_state: [0.20000000000000007, 34.80000000000001, 1.3877787807814457e-17, 0.3] mini_distance: 56.30354723761538
episode:  6800 Evaluation Average Reward: -2.7277258523294434 avg distance 499.15730613507924 mini_state: [3.0499999999999976, 37.64999999999985, 2.849999999999998, 0.3] mini_distance: 499.1573061350792
episode:  6900 Evaluation Average Reward: -0.13950500134774688 avg distance 16.064397047486384 mini_state: [1.9000000000000012, 33.45000000000009, 1.9000000000000008, 1.3877787807814457e-17] mini_distance: 16.064397047486388
episode:  7000 Evaluation Average Reward: -0.05865988230034995 avg distance 49.42392507602422 mini_state: [0.20000000000000007, 33.3000000000001, 2.1000000000000005, 0.10000000000000002] mini_distance: 49.423925076024226
episode:  7100 Evaluation Average Reward: -1.2630037547726152 avg distance 520.7132854716705 mini_state: [2.4000000000000004, 36.19999999999993, 3.049999999999997, 0.3] mini_distance: 497.69585692214827
episode:  7200 Evaluation Average Reward: -8.573157590010583 avg distance 490.3598934347121 mini_state: [0.30000000000000004, 34.900000000000006, 1.2500000000000004, 1.4000000000000006] mini_distance: 396.7475815517721
episode:  7300 Evaluation Average Reward: -1.6360581699073087 avg distance 42.96252750465265 mini_state: [0.4, 33.150000000000105, 2.0500000000000007, 1.3877787807814457e-17] mini_distance: 42.96252750465265
episode:  7400 Evaluation Average Reward: -11.237079687547682 avg distance 455.2973025297404 mini_state: [0.6000000000000001, 34.00000000000006, 1.4000000000000006, 1.4000000000000006] mini_distance: 381.49545809891845
episode:  7500 Evaluation Average Reward: -0.07191097266224857 avg distance 51.7141747497932 mini_state: [1.3500000000000008, 10.699999999999868, 0.9500000000000002, 0.44999999999999996] mini_distance: 51.71417474979321
episode:  7600 Evaluation Average Reward: -2.39618222448291 avg distance 56.332010384107875 mini_state: [0.9000000000000004, 34.50000000000003, 1.3877787807814457e-17, 0.3] mini_distance: 56.33201038410786
episode:  7700 Evaluation Average Reward: -5.752626909865103 avg distance 55.13327967016379 mini_state: [0.6500000000000001, 34.750000000000014, 1.3877787807814457e-17, 0.35] mini_distance: 55.133279670163795
episode:  7800 Evaluation Average Reward: -1.8085149565826453 avg distance 49.25476037039902 mini_state: [0.45, 32.35000000000015, 1.6500000000000008, 1.3877787807814457e-17] mini_distance: 49.25476037039902
episode:  7900 Evaluation Average Reward: 0.2501399141177266 avg distance 21.438540447740138 mini_state: [0.5, 32.15000000000016, 3.2499999999999964, 0.049999999999999906] mini_distance: 21.438540447740138
episode:  8000 Evaluation Average Reward: 0.007977633775583349 avg distance 13.392460675664832 mini_state: [1.3000000000000007, 11.099999999999874, 2.3499999999999996, 0.3] mini_distance: 13.392460675664829
episode:  8100 Evaluation Average Reward: -31.979009068590912 avg distance 515.7289915408965 mini_state: [1.4500000000000008, 35.949999999999946, 1.3500000000000005, 1.3500000000000005] mini_distance: 330.9883334539265
episode:  8200 Evaluation Average Reward: -0.7041173727763291 avg distance 54.913706160607674 mini_state: [0.5, 31.600000000000165, 1.1500000000000004, 1.3877787807814457e-17] mini_distance: 54.91370616060767
episode:  8300 Evaluation Average Reward: -12.112338481202029 avg distance 57.608075865529045 mini_state: [0.7000000000000002, 34.70000000000002, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.60807586552904
episode:  8400 Evaluation Average Reward: 0.40977049690465994 avg distance 56.817672000953635 mini_state: [0.4, 27.500000000000107, 0.9000000000000002, 1.3877787807814457e-17] mini_distance: 56.817672000953635
episode:  8500 Evaluation Average Reward: -0.18250693916686167 avg distance 55.73080714421478 mini_state: [2.050000000000001, 4.099999999999844, 0.7, 1.3877787807814457e-17] mini_distance: 55.73080714421477
episode:  8600 Evaluation Average Reward: -0.11356499395960536 avg distance 55.06836559151738 mini_state: [0.6000000000000001, 21.550000000000022, 1.3877787807814457e-17, 0.39999999999999997] mini_distance: 55.06836559151739
episode:  8700 Evaluation Average Reward: -0.357813165952906 avg distance 56.78941816494638 mini_state: [0.6000000000000001, 23.800000000000054, 1.3877787807814457e-17, 0.3] mini_distance: 56.7894181649464
episode:  8800 Evaluation Average Reward: -1.0874473716147186 avg distance 56.56354163898003 mini_state: [0.6000000000000001, 29.000000000000128, 1.3877787807814457e-17, 0.3] mini_distance: 56.563541638980034
episode:  8900 Evaluation Average Reward: -0.0234618793629069 avg distance 16.721610212083075 mini_state: [0.5, 40.59999999999968, 0.65, 0.7500000000000001] mini_distance: 16.72161021208307
episode:  9000 Evaluation Average Reward: -1.6462251140577047 avg distance 5.656591132545331 mini_state: [6.938893903907228e-17, 34.95, 1.1000000000000003, 1.0500000000000003] mini_distance: 5.656591132545331
episode:  9100 Evaluation Average Reward: -0.11472380354424801 avg distance 57.35169590424103 mini_state: [1.550000000000001, 35.05, 0.49999999999999994, 0.05000000000000002] mini_distance: 57.35169590424103
episode:  9200 Evaluation Average Reward: -1.3003289235481148 avg distance 57.71429669747745 mini_state: [0.8000000000000003, 35.05, 1.3877787807814457e-17, 0.15000000000000002] mini_distance: 57.71429669747745
episode:  9300 Evaluation Average Reward: -4.947249903438711 avg distance 50.98204682428982 mini_state: [0.4, 35.0, 1.3877787807814457e-17, 0.44999999999999996] mini_distance: 50.982046824289824
episode:  9400 Evaluation Average Reward: -7.335631163656752 avg distance 57.608075865529045 mini_state: [0.7000000000000002, 35.0, 0.49999999999999994, 1.3877787807814457e-17] mini_distance: 57.60807586552904
episode:  9500 Evaluation Average Reward: -0.15137058338672957 avg distance 55.19265526126914 mini_state: [0.35000000000000003, 26.150000000000087, 1.0500000000000003, 0.3] mini_distance: 55.19265526126913
episode:  9600 Evaluation Average Reward: 0.01280551070800576 avg distance 55.972107856440104 mini_state: [0.20000000000000007, 22.80000000000004, 1.2000000000000004, 0.25] mini_distance: 55.97210785644011
episode:  9700 Evaluation Average Reward: -0.2587089238077321 avg distance 524.6790702146216 mini_state: [1.0500000000000005, 14.849999999999927, 3.7999999999999945, 0.35] mini_distance: 428.55388602411915
episode:  9800 Evaluation Average Reward: -3.2135593965421605 avg distance 55.06102148218872 mini_state: [6.938893903907228e-17, 35.39999999999998, 0.25, 0.35] mini_distance: 55.06102148218872
episode:  9900 Evaluation Average Reward: 0.20628711769178687 avg distance 57.731476285063664 mini_state: [1.5000000000000009, 34.00000000000006, 0.3, 0.10000000000000002] mini_distance: 57.73147628506367
episode:  10000 Evaluation Average Reward: -0.0664470205724686 avg distance 51.32108834470593 mini_state: [2.050000000000001, 35.05, 0.9000000000000002, 0.3] mini_distance: 51.321088344705935
episode:  10100 Evaluation Average Reward: -0.47221191357526954 avg distance 57.11441288245355 mini_state: [1.2000000000000006, 18.349999999999977, 0.6, 0.05000000000000002] mini_distance: 57.11441288245355
episode:  10200 Evaluation Average Reward: -7.441240124308074 avg distance 435.58009263562906 mini_state: [0.15000000000000008, 38.099999999999824, 2.3, 1.3500000000000005] mini_distance: 372.9719137443486
episode:  10300 Evaluation Average Reward: -9.1123432327064 avg distance 56.27319091687521 mini_state: [6.938893903907228e-17, 35.39999999999998, 0.2, 0.3] mini_distance: 56.2731909168752
episode:  10400 Evaluation Average Reward: -2.158685398014178 avg distance 504.27725748920705 mini_state: [1.4500000000000008, 39.34999999999975, 3.4499999999999957, 0.7500000000000001] mini_distance: 504.277257489207
episode:  10500 Evaluation Average Reward: -0.49585742852098685 avg distance 57.813069392410725 mini_state: [0.25000000000000006, 26.150000000000087, 0.25, 1.3877787807814457e-17] mini_distance: 57.813069392410725
episode:  10600 Evaluation Average Reward: -4.507218095342389 avg distance 57.766165502553235 mini_state: [0.4, 34.80000000000001, 0.39999999999999997, 1.3877787807814457e-17] mini_distance: 57.766165502553235
episode:  10700 Evaluation Average Reward: -0.5043667868002967 avg distance 57.81740235993537 mini_state: [6.938893903907228e-17, 28.950000000000127, 0.8500000000000002, 0.05000000000000002] mini_distance: 57.817402359935365
episode:  10800 Evaluation Average Reward: -6.673261332405594 avg distance 57.80091783192462 mini_state: [0.4, 34.60000000000002, 0.3, 1.3877787807814457e-17] mini_distance: 57.800917831924636
episode:  10900 Evaluation Average Reward: -16.57988723289684 avg distance 475.16636752072344 mini_state: [1.4000000000000008, 33.90000000000006, 0.49999999999999994, 1.4000000000000006] mini_distance: 361.4427879668067
episode:  11000 Evaluation Average Reward: -2.298992008278198 avg distance 33.980879401442515 mini_state: [6.938893903907228e-17, 34.550000000000026, 0.35, 0.65] mini_distance: 33.980879401442515
episode:  11100 Evaluation Average Reward: 0.019177881585118052 avg distance 37.108430008022026 mini_state: [6.938893903907228e-17, 54.449999999998894, 0.39999999999999997, 0.5499999999999999] mini_distance: 37.108430008022026
episode:  11200 Evaluation Average Reward: -4.179535790123196 avg distance 57.04838295512623 mini_state: [6.938893903907228e-17, 35.29999999999998, 0.2, 0.25] mini_distance: 57.04838295512623
episode:  11300 Evaluation Average Reward: -0.10514917926180946 avg distance 57.24464340775056 mini_state: [0.05000000000000007, 42.39999999999958, 1.3000000000000005, 0.15000000000000002] mini_distance: 57.24464340775056
episode:  11400 Evaluation Average Reward: -0.2637036739887373 avg distance 57.80974906159521 mini_state: [0.8000000000000003, 34.85000000000001, 0.2, 0.05000000000000002] mini_distance: 57.80974906159523
episode:  11500 Evaluation Average Reward: -0.0472643224240982 avg distance 57.714480219788086 mini_state: [0.8500000000000003, 31.800000000000168, 0.2, 0.15000000000000002] mini_distance: 57.71448021978807
episode:  11600 Evaluation Average Reward: -0.010909449684056754 avg distance 48.07462333415305 mini_state: [1.1000000000000005, 34.30000000000004, 0.05000000000000002, 0.49999999999999994] mini_distance: 48.07462333415306
a1,a2,r1,r2:[6.938893903907228e-17, 35.29999999999998, 3.2499999999999964, 1.0000000000000002]

episode:  11700 Evaluation Average Reward: 0.13905886063900583 avg distance 0.791626168561143 mini_state: [6.938893903907228e-17, 35.29999999999998, 3.2499999999999964, 1.0000000000000002] mini_distance: 0.791626168561143
[[0.4, 34.80000000000001, 1.3877787807814457e-17, 0.3], [0.4, 34.80000000000001, 1.3877787807814457e-17, 0.3], [0.7000000000000002, 34.70000000000002, 0.2, 1.3877787807814457e-17], [0.7000000000000002, 35.0, 0.49999999999999994, 1.3877787807814457e-17], [0.7000000000000002, 35.0, 0.49999999999999994, 1.3877787807814457e-17], [0.4, 94.99999999999659, 0.2, 0.3], [0.4, 94.99999999999659, 0.2, 0.3], [0.4, 35.0, 0.2, 0.3], [1.8500000000000012, 36.7499999999999, 0.35, 0.44999999999999996], [0.4, 49.499999999999176, 1.1500000000000004, 1.2500000000000004], [0.4, 21.50000000000002, 0.49999999999999994, 1.3877787807814457e-17], [0.4, 35.249999999999986, 0.44999999999999996, 1.3877787807814457e-17], [4.299999999999994, 67.04999999999818, 0.39999999999999997, 0.10000000000000002], [5.19999999999999, 67.39999999999816, 0.2, 0.3], [6.938893903907228e-17, 34.70000000000002, 0.49999999999999994, 0.65], [6.938893903907228e-17, 34.60000000000002, 0.6, 0.7000000000000001], [6.799999999999985, 68.19999999999811, 0.2, 0.3], [10.200000000000012, 69.89999999999802, 0.2, 0.3], [6.938893903907228e-17, 18.849999999999984, 2.6999999999999984, 0.3], [1.1000000000000005, 35.0, 0.9000000000000002, 1.3877787807814457e-17], [0.7000000000000002, 35.14999999999999, 0.65, 1.3877787807814457e-17], [0.6000000000000001, 35.19999999999999, 1.3877787807814457e-17, 0.49999999999999994], [0.20000000000000007, 34.70000000000002, 1.3877787807814457e-17, 0.2], [6.938893903907228e-17, 34.60000000000002, 0.6, 0.3], [6.938893903907228e-17, 35.099999999999994, 0.3, 0.2], [0.20000000000000007, 35.19999999999999, 1.3877787807814457e-17, 0.49999999999999994], [0.4, 35.29999999999998, 0.2, 1.3877787807814457e-17], [0.45, 34.95, 1.3877787807814457e-17, 0.3], [0.6000000000000001, 34.80000000000001, 1.3877787807814457e-17, 0.3], [1.3000000000000007, 34.400000000000034, 0.25, 1.3877787807814457e-17], [0.30000000000000004, 36.7499999999999, 0.49999999999999994, 1.3877787807814457e-17], [0.10000000000000007, 34.70000000000002, 0.49999999999999994, 1.3877787807814457e-17], [0.4, 34.70000000000002, 0.49999999999999994, 1.3877787807814457e-17], [6.938893903907228e-17, 34.550000000000026, 0.35, 0.15000000000000002], [0.4, 27.900000000000112, 2.2, 1.4500000000000006], [0.10000000000000007, 11.59999999999988, 1.5500000000000007, 1.950000000000001], [6.938893903907228e-17, 35.0, 0.3, 0.6], [6.938893903907228e-17, 23.700000000000053, 1.0000000000000002, 0.3], [6.938893903907228e-17, 35.249999999999986, 1.1500000000000004, 0.5499999999999999], [1.3500000000000008, 35.0, 0.2, 0.3], [3.499999999999996, 35.0, 1.3877787807814457e-17, 0.49999999999999994], [6.938893903907228e-17, 30.100000000000144, 0.2, 0.3], [6.938893903907228e-17, 17.79999999999997, 0.2, 0.3], [1.550000000000001, 8.449999999999836, 0.8000000000000002, 1.1000000000000003], [8.799999999999992, 35.0, 1.2000000000000004, 0.3], [5.699999999999989, 48.49999999999923, 2.3499999999999996, 0.6], [7.099999999999984, 41.49999999999963, 1.3877787807814457e-17, 0.3], [6.938893903907228e-17, 34.60000000000002, 0.2, 0.3], [0.20000000000000007, 34.80000000000001, 1.3877787807814457e-17, 0.3], [0.15000000000000008, 35.19999999999999, 1.3877787807814457e-17, 0.3], [6.938893903907228e-17, 35.0, 0.2, 0.3], [0.6000000000000001, 34.80000000000001, 1.3877787807814457e-17, 0.49999999999999994], [0.4, 35.0, 0.2, 1.4000000000000006], [0.4, 36.04999999999994, 1.2500000000000004, 1.3500000000000005], [0.4, 35.0, 0.2, 0.3], [0.4, 35.0, 0.2, 0.3], [0.4, 35.0, 0.2, 0.3], [0.4, 35.0, 0.49999999999999994, 1.3877787807814457e-17], [0.4, 6.399999999999836, 0.2, 0.3], [0.45, 8.099999999999831, 0.35, 0.25], [0.4, 34.400000000000034, 0.8000000000000002, 1.3877787807814457e-17], [6.938893903907228e-17, 42.94999999999955, 4.3499999999999925, 0.5499999999999999], [0.4, 34.80000000000001, 1.3877787807814457e-17, 0.3], [1.650000000000001, 23.000000000000043, 0.5499999999999998, 1.6000000000000008], [6.938893903907228e-17, 28.950000000000127, 1.2000000000000004, 0.3], [6.938893903907228e-17, 24.550000000000065, 2.9499999999999975, 0.3], [2.150000000000001, 33.2500000000001, 3.149999999999997, 0.3], [0.20000000000000007, 34.80000000000001, 1.3877787807814457e-17, 0.3], [3.0499999999999976, 37.64999999999985, 2.849999999999998, 0.3], [1.9000000000000012, 33.45000000000009, 1.9000000000000008, 1.3877787807814457e-17], [0.20000000000000007, 33.3000000000001, 2.1000000000000005, 0.10000000000000002], [2.4000000000000004, 36.19999999999993, 3.049999999999997, 0.3], [0.30000000000000004, 34.900000000000006, 1.2500000000000004, 1.4000000000000006], [0.4, 33.150000000000105, 2.0500000000000007, 1.3877787807814457e-17], [0.6000000000000001, 34.00000000000006, 1.4000000000000006, 1.4000000000000006], [1.3500000000000008, 10.699999999999868, 0.9500000000000002, 0.44999999999999996], [0.9000000000000004, 34.50000000000003, 1.3877787807814457e-17, 0.3], [0.6500000000000001, 34.750000000000014, 1.3877787807814457e-17, 0.35], [0.45, 32.35000000000015, 1.6500000000000008, 1.3877787807814457e-17], [0.5, 32.15000000000016, 3.2499999999999964, 0.049999999999999906], [1.3000000000000007, 11.099999999999874, 2.3499999999999996, 0.3], [1.4500000000000008, 35.949999999999946, 1.3500000000000005, 1.3500000000000005], [0.5, 31.600000000000165, 1.1500000000000004, 1.3877787807814457e-17], [0.7000000000000002, 34.70000000000002, 0.49999999999999994, 1.3877787807814457e-17], [0.4, 27.500000000000107, 0.9000000000000002, 1.3877787807814457e-17], [2.050000000000001, 4.099999999999844, 0.7, 1.3877787807814457e-17], [0.6000000000000001, 21.550000000000022, 1.3877787807814457e-17, 0.39999999999999997], [0.6000000000000001, 23.800000000000054, 1.3877787807814457e-17, 0.3], [0.6000000000000001, 29.000000000000128, 1.3877787807814457e-17, 0.3], [0.5, 40.59999999999968, 0.65, 0.7500000000000001], [6.938893903907228e-17, 34.95, 1.1000000000000003, 1.0500000000000003], [1.550000000000001, 35.05, 0.49999999999999994, 0.05000000000000002], [0.8000000000000003, 35.05, 1.3877787807814457e-17, 0.15000000000000002], [0.4, 35.0, 1.3877787807814457e-17, 0.44999999999999996], [0.7000000000000002, 35.0, 0.49999999999999994, 1.3877787807814457e-17], [0.35000000000000003, 26.150000000000087, 1.0500000000000003, 0.3], [0.20000000000000007, 22.80000000000004, 1.2000000000000004, 0.25], [1.0500000000000005, 14.849999999999927, 3.7999999999999945, 0.35], [6.938893903907228e-17, 35.39999999999998, 0.25, 0.35], [1.5000000000000009, 34.00000000000006, 0.3, 0.10000000000000002], [2.050000000000001, 35.05, 0.9000000000000002, 0.3], [1.2000000000000006, 18.349999999999977, 0.6, 0.05000000000000002], [0.15000000000000008, 38.099999999999824, 2.3, 1.3500000000000005], [6.938893903907228e-17, 35.39999999999998, 0.2, 0.3], [1.4500000000000008, 39.34999999999975, 3.4499999999999957, 0.7500000000000001], [0.25000000000000006, 26.150000000000087, 0.25, 1.3877787807814457e-17], [0.4, 34.80000000000001, 0.39999999999999997, 1.3877787807814457e-17], [6.938893903907228e-17, 28.950000000000127, 0.8500000000000002, 0.05000000000000002], [0.4, 34.60000000000002, 0.3, 1.3877787807814457e-17], [1.4000000000000008, 33.90000000000006, 0.49999999999999994, 1.4000000000000006], [6.938893903907228e-17, 34.550000000000026, 0.35, 0.65], [6.938893903907228e-17, 54.449999999998894, 0.39999999999999997, 0.5499999999999999], [6.938893903907228e-17, 35.29999999999998, 0.2, 0.25], [0.05000000000000007, 42.39999999999958, 1.3000000000000005, 0.15000000000000002], [0.8000000000000003, 34.85000000000001, 0.2, 0.05000000000000002], [0.8500000000000003, 31.800000000000168, 0.2, 0.15000000000000002], [1.1000000000000005, 34.30000000000004, 0.05000000000000002, 0.49999999999999994], [6.938893903907228e-17, 35.29999999999998, 3.2499999999999964, 1.0000000000000002]]
[56.30797270645088, 56.30797270645088, 57.812062930958255, 57.60807586552904, 57.60807586552904, 53.73870380247611, 53.73870380247611, 56.28694083658173, 50.492269725464794, 343.7038341948021, 57.69822740314681, 57.73717099110682, 57.21589124723142, 54.858213474532405, 33.89196306090067, 27.879796263756155, 54.810493185618135, 54.70920308304224, 56.99177430702014, 55.087167755763474, 57.26923747073752, 47.82526402720589, 57.498827750431, 56.307768716249676, 57.49393584177657, 47.792650753194394, 57.81484490094833, 56.302595339723105, 56.312399174347206, 57.79003712196946, 57.72829576504873, 57.788459262897945, 57.69822740314681, 57.714037962333954, 350.2655532312241, 486.08811967854444, 39.19390741215944, 56.78048383337779, 43.82261586417478, 56.27854144892895, 48.11994610975035, 56.5025666776551, 57.037594968889735, 21.48117557655727, 12.97231085412798, 483.42941503602844, 56.16768184662269, 56.307768716249676, 56.30354723761538, 56.28515205183982, 56.29047781847488, 47.9331785805754, 393.41817832255845, 305.5934406696345, 56.28694083658173, 56.28694083658173, 56.28694083658173, 57.69822740314681, 57.533244701412066, 57.60551169687499, 57.15749785778725, 41.05294286911097, 56.30797270645088, 457.5715208780375, 56.55242951998976, 56.74351404877101, 501.3499202369049, 56.30354723761538, 499.1573061350792, 16.064397047486388, 49.423925076024226, 497.69585692214827, 396.7475815517721, 42.96252750465265, 381.49545809891845, 51.71417474979321, 56.33201038410786, 55.133279670163795, 49.25476037039902, 21.438540447740138, 13.392460675664829, 330.9883334539265, 54.91370616060767, 57.60807586552904, 56.817672000953635, 55.73080714421477, 55.06836559151739, 56.7894181649464, 56.563541638980034, 16.72161021208307, 5.656591132545331, 57.35169590424103, 57.71429669747745, 50.982046824289824, 57.60807586552904, 55.19265526126913, 55.97210785644011, 428.55388602411915, 55.06102148218872, 57.73147628506367, 51.321088344705935, 57.11441288245355, 372.9719137443486, 56.2731909168752, 504.277257489207, 57.813069392410725, 57.766165502553235, 57.817402359935365, 57.800917831924636, 361.4427879668067, 33.980879401442515, 37.108430008022026, 57.04838295512623, 57.24464340775056, 57.80974906159523, 57.71448021978807, 48.07462333415306, 0.791626168561143]

Process finished with exit code 0

