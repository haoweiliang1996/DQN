/usr/bin/python3.5 /home/haowei/PycharmProjects/DQN/four.py
fig size: 80.0 DPI, size in inches [ 3.  4.]
env init ok
episode:20000,stepTimes:1200,stepSize:0.05,gbest: False,Ok_eps:1.0,init_state: [0.1, 30, 0.1, 0.1],agent_saved:True range: [0, 30, 30, 50]
episode:  0 Evaluation Average Reward: -2.6284725185811766 avg distance 521.0417749599183 mini_state: [2.8999999999999977, 32.79999999999998, 2.8999999999999977, 0.1] mini_distance: 510.3709872786073
/home/haowei/.local/lib/python3.5/site-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented
  warnings.warn(str, mplDeprecation)
episode:  100 Evaluation Average Reward: -0.4727144441469392 avg distance 510.382061899306 mini_state: [2.8999999999999977, 47.199999999999164, 2.8999999999999977, 0.1] mini_distance: 510.3820312183885
episode:  200 Evaluation Average Reward: -25.07212767207822 avg distance 57.8166996206711 mini_state: [0.2, 30.1, 0.2, 0.0] mini_distance: 57.8166996206711
episode:  300 Evaluation Average Reward: -6.558659430512024 avg distance 489.8548931553555 mini_state: [1.5000000000000007, 29.9, 2.1000000000000005, 1.4000000000000006] mini_distance: 427.21769307421556
episode:  400 Evaluation Average Reward: -0.9683258704764238 avg distance 57.80155003330208 mini_state: [0.0, 27.549999999999965, 2.549999999999999, 0.1] mini_distance: 57.80155003330208
episode:  500 Evaluation Average Reward: 0.07559576727016389 avg distance 57.80158088637957 mini_state: [0.0, 27.499999999999964, 2.5999999999999988, 0.1] mini_distance: 57.80158088637957
episode:  600 Evaluation Average Reward: -4.391396982455131 avg distance 56.03850654763998 mini_state: [0.1, 28.59999999999998, 1.6000000000000008, 0.0] mini_distance: 56.038506547639976
episode:  700 Evaluation Average Reward: -2.544617359904162 avg distance 54.95909370148918 mini_state: [0.1, 28.349999999999977, 1.850000000000001, 0.0] mini_distance: 54.959093701489174
episode:  800 Evaluation Average Reward: -28.770922395230446 avg distance 57.80002687998804 mini_state: [0.1, 30.1, 0.0, 0.1] mini_distance: 57.80002687998804
episode:  900 Evaluation Average Reward: -0.04372447758995925 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  1000 Evaluation Average Reward: -0.11606376725722957 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  1100 Evaluation Average Reward: -0.1896706008179946 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  1200 Evaluation Average Reward: -0.24443102538508588 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  1300 Evaluation Average Reward: -0.08554053382280352 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  1400 Evaluation Average Reward: 0.263235351165409 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  1500 Evaluation Average Reward: 0.08227601687725024 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  1600 Evaluation Average Reward: -0.2825419073917551 avg distance 57.81770276295556 mini_state: [0.7000000000000001, 1.9499999999997093, 1.3877787807814457e-17, 0.1] mini_distance: 57.817702762955555
episode:  1700 Evaluation Average Reward: -0.4968929239838584 avg distance 57.81715518445024 mini_state: [0.9000000000000002, 2.999999999999706, 1.3877787807814457e-17, 0.1] mini_distance: 57.81715518445024
episode:  1800 Evaluation Average Reward: 0.30687378093633066 avg distance 57.81616640989232 mini_state: [1.4500000000000006, 5.049999999999699, 1.3877787807814457e-17, 0.1] mini_distance: 57.81616640989232
episode:  1900 Evaluation Average Reward: 0.1495925039109726 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  2000 Evaluation Average Reward: 0.08737794776234507 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  2100 Evaluation Average Reward: -1.5975068027442847 avg distance 503.6058543238506 mini_state: [0.8000000000000002, 30.300000000000004, 4.049999999999994, 0.8500000000000002] mini_distance: 479.1325502840116
episode:  2200 Evaluation Average Reward: -3.5991518137112304 avg distance 518.8899226771864 mini_state: [0.25, 30.150000000000002, 5.14999999999999, 1.1500000000000004] mini_distance: 438.81092775280473
episode:  2300 Evaluation Average Reward: 0.18261050075720653 avg distance 57.81480333233843 mini_state: [1.7000000000000008, 6.049999999999695, 0.049999999999999906, 0.1] mini_distance: 57.814803332338414
episode:  2400 Evaluation Average Reward: -10.08141578254112 avg distance 457.80289269864727 mini_state: [0.1, 27.749999999999968, 1.7000000000000008, 1.5000000000000007] mini_distance: 414.0456740896771
episode:  2500 Evaluation Average Reward: -5.05529063288556 avg distance 479.9716346939975 mini_state: [0.1, 26.49999999999995, 2.2, 1.5000000000000007] mini_distance: 374.0488850243637
episode:  2600 Evaluation Average Reward: -18.42349846695351 avg distance 478.52677445478747 mini_state: [0.1, 30.0, 1.4500000000000006, 1.4500000000000006] mini_distance: 366.48432622377777
episode:  2700 Evaluation Average Reward: 0.03780980783295203 avg distance 57.807705833469484 mini_state: [10.700000000000017, 26.299999999999947, 0.0, 0.1] mini_distance: 57.80770583346947
episode:  2800 Evaluation Average Reward: -1.9330828267673357 avg distance 546.5660104687956 mini_state: [3.699999999999995, 30.70000000000001, 2.6999999999999984, 0.1] mini_distance: 499.6085821860931
episode:  2900 Evaluation Average Reward: -0.1708220024543583 avg distance 57.8031270232206 mini_state: [12.650000000000045, 24.799999999999926, 0.049999999999999906, 0.1] mini_distance: 57.8031270232206
episode:  3000 Evaluation Average Reward: -0.5613071438006009 avg distance 463.04867884078783 mini_state: [0.49999999999999994, 34.04999999999991, 4.6499999999999915, 0.8000000000000002] mini_distance: 463.04867884078783
episode:  3100 Evaluation Average Reward: -1.0986701540771828 avg distance 546.7884965867953 mini_state: [0.49999999999999994, 33.94999999999992, 4.849999999999991, 0.49999999999999994] mini_distance: 546.7884965867954
episode:  3200 Evaluation Average Reward: -1.3316573666819067 avg distance 438.49096888255156 mini_state: [0.39999999999999997, 34.349999999999895, 5.04999999999999, 0.39999999999999997] mini_distance: 438.4909688825516
episode:  3300 Evaluation Average Reward: -1.6154022174844642 avg distance 552.4293882551764 mini_state: [0.35, 34.499999999999886, 5.399999999999989, 0.49999999999999994] mini_distance: 552.4293882551764
episode:  3400 Evaluation Average Reward: -0.8203991539429227 avg distance 537.1850151700269 mini_state: [9.850000000000005, 26.099999999999945, 2.0500000000000007, 0.2] mini_distance: 500.4613328022885
episode:  3500 Evaluation Average Reward: -14.48582622458944 avg distance 540.444798378058 mini_state: [0.7500000000000001, 29.29999999999999, 1.4500000000000006, 1.4500000000000006] mini_distance: 364.814717819643
episode:  3600 Evaluation Average Reward: -19.145011429201862 avg distance 534.3399290019727 mini_state: [0.1, 31.35000000000002, 0.1, 1.4500000000000006] mini_distance: 409.34027624891564
episode:  3700 Evaluation Average Reward: -2.519325237778294 avg distance 542.1270921951732 mini_state: [0.44999999999999996, 30.0, 4.299999999999993, 1.2000000000000004] mini_distance: 507.13887902641335
episode:  3800 Evaluation Average Reward: -24.953224844888442 avg distance 57.542193616296956 mini_state: [0.2, 30.0, 0.0, 0.2] mini_distance: 57.542193616296956
episode:  3900 Evaluation Average Reward: -34.239868022657774 avg distance 57.8001502866649 mini_state: [0.1, 29.9, 0.0, 0.1] mini_distance: 57.80015028666491
episode:  4000 Evaluation Average Reward: -17.0229184909927 avg distance 458.4203718285953 mini_state: [1.4500000000000006, 30.0, 0.1, 1.4500000000000006] mini_distance: 361.5726922853337
episode:  4100 Evaluation Average Reward: -15.1799277339018 avg distance 496.30109598258457 mini_state: [0.1, 30.0, 1.4500000000000006, 1.4500000000000006] mini_distance: 366.48432622377777
episode:  4200 Evaluation Average Reward: 0.21717898255205623 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  4300 Evaluation Average Reward: 0.04630028268754745 avg distance 57.800038267424874 mini_state: [0.0, 30.0, 0.1, 0.1] mini_distance: 57.800038267424874
episode:  4400 Evaluation Average Reward: -0.3505481635966512 avg distance 57.78652797218224 mini_state: [1.900000000000001, 49.999999999999005, 0.1, 0.1] mini_distance: 57.786527972182235
episode:  4500 Evaluation Average Reward: 0.08059467004420034 avg distance 57.815405932434615 mini_state: [0.0, 5.0999999999996986, 0.1, 0.1] mini_distance: 57.815405932434615
episode:  4600 Evaluation Average Reward: -0.15636680217335053 avg distance 57.80973561586252 mini_state: [0.2, 4.099999999999702, 0.3, 0.0] mini_distance: 57.80973561586252
episode:  4700 Evaluation Average Reward: 0.14283749804051765 avg distance 57.813069392410725 mini_state: [0.25, 4.099999999999702, 0.25, 0.0] mini_distance: 57.813069392410725
episode:  4800 Evaluation Average Reward: 0.257377418367684 avg distance 57.81531333497152 mini_state: [0.1, 5.149999999999698, 0.1, 0.1] mini_distance: 57.81531333497151
episode:  4900 Evaluation Average Reward: 0.18314650357855866 avg distance 535.0489242061608 mini_state: [3.1999999999999966, 22.499999999999893, 2.799999999999998, 0.35] mini_distance: 481.8132479063649
episode:  5000 Evaluation Average Reward: 0.14816706568780968 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  5100 Evaluation Average Reward: -4.896759811393348 avg distance 511.3896039323481 mini_state: [4.199999999999993, 24.899999999999928, 0.8500000000000002, 1.5500000000000007] mini_distance: 438.23726994273534
episode:  5200 Evaluation Average Reward: -0.2692797469443958 avg distance 362.4790982676124 mini_state: [2.9499999999999975, 25.89999999999994, 2.0500000000000007, 1.3500000000000005] mini_distance: 362.47909826761247
episode:  5300 Evaluation Average Reward: -0.029126019633438933 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  5400 Evaluation Average Reward: -0.01601196864232194 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  5500 Evaluation Average Reward: -0.08175908051065196 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  5600 Evaluation Average Reward: 0.002417851630635492 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  5700 Evaluation Average Reward: -0.046567468044642936 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  5800 Evaluation Average Reward: -0.011886177785171901 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  5900 Evaluation Average Reward: -0.07227874828467515 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  6000 Evaluation Average Reward: -0.010836251605659906 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  6100 Evaluation Average Reward: 0.0479739801335636 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  6200 Evaluation Average Reward: -0.036240870545152515 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  6300 Evaluation Average Reward: -0.13820749871785382 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  6400 Evaluation Average Reward: 0.37105355312764904 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  6500 Evaluation Average Reward: -0.1001932098562082 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  6600 Evaluation Average Reward: -0.10395040908880228 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  6700 Evaluation Average Reward: -0.0038824636883040393 avg distance 28.385106717812754 mini_state: [0.1, 31.45000000000002, 4.3499999999999925, 0.1] mini_distance: 28.385106717812757
episode:  6800 Evaluation Average Reward: 0.1808739509697937 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  6900 Evaluation Average Reward: -0.8435458012055003 avg distance 561.2579806100124 mini_state: [0.1, 23.899999999999913, 7.89999999999998, 0.1] mini_distance: 542.8432734240519
episode:  7000 Evaluation Average Reward: 0.02065916880412956 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  7100 Evaluation Average Reward: -0.0021343097578084167 avg distance 2.6039520002730883 mini_state: [0.1, 30.0, 0.1, 0.9500000000000003] mini_distance: 2.603952000273088
episode:  7200 Evaluation Average Reward: 0.15951672718154036 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  7300 Evaluation Average Reward: -4.003874525815616 avg distance 438.94991755215653 mini_state: [5.14999999999999, 36.299999999999784, 1.3500000000000005, 1.3500000000000005] mini_distance: 438.9499175521565
episode:  7400 Evaluation Average Reward: -0.11249487984405719 avg distance 10.788536417110821 mini_state: [5.999999999999987, 31.600000000000023, 0.1, 1.1000000000000003] mini_distance: 10.788536417110821
episode:  7500 Evaluation Average Reward: -3.2476428060856084 avg distance 475.8231690340992 mini_state: [6.849999999999984, 33.19999999999996, 0.1, 1.4500000000000006] mini_distance: 474.6853537715195
episode:  7600 Evaluation Average Reward: -0.05021258202780959 avg distance 57.79997656414923 mini_state: [0.1, 30.0, 0.1, 0.1] mini_distance: 57.79997656414923
episode:  7700 Evaluation Average Reward: -1.5885157887392323 avg distance 557.8493127492823 mini_state: [5.649999999999988, 40.499999999999545, 2.3999999999999995, 0.1] mini_distance: 506.89835954940236
episode:  7800 Evaluation Average Reward: -2.1509769702102703 avg distance 525.3915258346076 mini_state: [3.949999999999994, 37.04999999999974, 2.6499999999999986, 0.1] mini_distance: 498.67938132592764
episode:  7900 Evaluation Average Reward: -0.025677513938517953 avg distance 11.436846601202548 mini_state: [1.900000000000001, 32.45, 2.1000000000000005, 0.1] mini_distance: 11.436846601202548
episode:  8000 Evaluation Average Reward: -0.11808675934692615 avg distance 57.2955609615958 mini_state: [0.1, 31.000000000000014, 1.1000000000000003, 0.1] mini_distance: 57.295560961595804
episode:  8100 Evaluation Average Reward: 0.01861632854806686 avg distance 22.28226232179071 mini_state: [0.6, 39.799999999999585, 3.149999999999997, 0.1] mini_distance: 22.28226232179071
episode:  8200 Evaluation Average Reward: -0.1513245825787567 avg distance 57.12079459019098 mini_state: [0.1, 31.100000000000016, 1.2000000000000004, 0.1] mini_distance: 57.12079459019098
episode:  8300 Evaluation Average Reward: -0.18366944558601858 avg distance 57.79973557596433 mini_state: [0.1, 30.0, 0.15000000000000002, 0.1] mini_distance: 57.79973557596433
episode:  8400 Evaluation Average Reward: -1.1826065693332646 avg distance 57.799637198171055 mini_state: [1.3877787807814457e-17, 30.65000000000001, 2.0500000000000007, 0.1] mini_distance: 57.799637198171055
episode:  8500 Evaluation Average Reward: -2.7242634090074582 avg distance 496.2849270459318 mini_state: [2.6999999999999984, 30.70000000000001, 2.9499999999999975, 0.1] mini_distance: 496.28492704593185
episode:  8600 Evaluation Average Reward: -0.02808595407814031 avg distance 16.448285878677744 mini_state: [1.4000000000000004, 30.65000000000001, 2.1000000000000005, 0.1] mini_distance: 16.44828587867774
episode:  8700 Evaluation Average Reward: 0.06907310850496111 avg distance 33.436196696717104 mini_state: [0.9000000000000002, 31.200000000000017, 1.900000000000001, 0.1] mini_distance: 33.436196696717104
episode:  8800 Evaluation Average Reward: -0.12922592946205724 avg distance 57.76956278992252 mini_state: [0.7000000000000001, 29.39999999999999, 0.3, 0.1] mini_distance: 57.769562789922524
episode:  8900 Evaluation Average Reward: -1.081388976591313 avg distance 57.80186622617539 mini_state: [2.1000000000000005, 28.749999999999982, 0.0, 0.1] mini_distance: 57.80186622617539
episode:  9000 Evaluation Average Reward: -4.762445782606087 avg distance 477.9337539425177 mini_state: [2.1500000000000004, 26.59999999999995, 0.7500000000000001, 1.5000000000000007] mini_distance: 369.7626712856416
episode:  9100 Evaluation Average Reward: -0.9924424715073672 avg distance 525.708190382656 mini_state: [1.4500000000000006, 22.649999999999896, 1.5500000000000007, 1.5500000000000007] mini_distance: 381.8276671502587
episode:  9200 Evaluation Average Reward: -1.193096947970577 avg distance 511.3346054981198 mini_state: [3.4499999999999957, 19.44999999999985, 0.35, 1.6500000000000008] mini_distance: 389.4540005534521
episode:  9300 Evaluation Average Reward: 0.3104609526995501 avg distance 57.42584037225906 mini_state: [0.049999999999999906, 3.599999999999704, 1.2500000000000004, 0.1] mini_distance: 57.42584037225907
episode:  9400 Evaluation Average Reward: -1.1665193598824335 avg distance 50.3302626884517 mini_state: [0.049999999999999684, 29.799999999999997, 2.499999999999999, 0.39999999999999997] mini_distance: 50.330262688451704
episode:  9500 Evaluation Average Reward: -0.7244885554646169 avg distance 39.97920119310256 mini_state: [0.049999999999999906, 26.899999999999956, 3.149999999999997, 0.5499999999999999] mini_distance: 39.97920119310257
episode:  9600 Evaluation Average Reward: -0.9655386710886494 avg distance 57.23847994122379 mini_state: [1.3877787807814457e-17, 26.54999999999995, 3.599999999999995, 0.25] mini_distance: 57.23847994122378
episode:  9700 Evaluation Average Reward: -9.450897311629507 avg distance 537.9070316315795 mini_state: [2.4499999999999993, 29.049999999999986, 2.499999999999999, 1.2500000000000004] mini_distance: 484.1080796414052
episode:  9800 Evaluation Average Reward: -0.1916075355325088 avg distance 538.6741107351888 mini_state: [2.5999999999999988, 30.65000000000001, 2.9499999999999975, 0.1] mini_distance: 451.77376420650387
episode:  9900 Evaluation Average Reward: 0.6234858329117456 avg distance 57.813285612377754 mini_state: [1.0000000000000002, 9.349999999999707, 1.3877787807814457e-17, 0.1] mini_distance: 57.81328561237775
episode:  10000 Evaluation Average Reward: -0.1779991381099749 avg distance 57.81296893284484 mini_state: [0.8000000000000002, 9.699999999999712, 1.3877787807814457e-17, 0.1] mini_distance: 57.812968932844846
episode:  10100 Evaluation Average Reward: -0.11278137468297636 avg distance 57.81377008169456 mini_state: [1.3877787807814457e-17, 7.749999999999689, 2.3, 0.1] mini_distance: 57.813770081694564
episode:  10200 Evaluation Average Reward: -0.11245780474478274 avg distance 57.815436798312604 mini_state: [1.3877787807814457e-17, 5.049999999999699, 1.3500000000000005, 0.1] mini_distance: 57.81543679831262
episode:  10300 Evaluation Average Reward: 0.07106916138369562 avg distance 57.8156528602572 mini_state: [1.3877787807814457e-17, 4.6999999999997, 1.4500000000000006, 0.1] mini_distance: 57.81565286025722
episode:  10400 Evaluation Average Reward: -0.05986750820769429 avg distance 26.307174214174985 mini_state: [2.1500000000000004, 15.19999999999979, 1.6000000000000008, 1.3877787807814457e-17] mini_distance: 26.30717421417499
episode:  10500 Evaluation Average Reward: -0.40558324250904443 avg distance 57.78591119429431 mini_state: [2.8999999999999977, 49.999999999999005, 0.1, 0.1] mini_distance: 57.78591119429431
episode:  10600 Evaluation Average Reward: 0.22695826897001842 avg distance 8.005832814428404 mini_state: [4.149999999999993, 14.249999999999776, 1.800000000000001, 0.049999999999999906] mini_distance: 8.005832814428404
episode:  10700 Evaluation Average Reward: -1.4904891251608219 avg distance 503.0640784913313 mini_state: [3.899999999999994, 17.099999999999817, 1.2000000000000004, 1.7000000000000008] mini_distance: 434.9331604410503
episode:  10800 Evaluation Average Reward: -1.5864037099241184 avg distance 503.2204143787894 mini_state: [3.1999999999999966, 20.74999999999987, 0.7500000000000001, 1.6000000000000008] mini_distance: 354.4756850491927
episode:  10900 Evaluation Average Reward: -0.02963587118481444 avg distance 57.78530104353867 mini_state: [0.9000000000000002, 21.899999999999885, 0.25, 0.1] mini_distance: 57.78530104353866
episode:  11000 Evaluation Average Reward: -0.05609900025787265 avg distance 55.83318237704724 mini_state: [0.8500000000000002, 27.699999999999967, 0.8500000000000002, 0.2] mini_distance: 55.83318237704722
episode:  11100 Evaluation Average Reward: 0.06802549411947723 avg distance 25.560818361702207 mini_state: [0.3, 29.549999999999994, 0.3, 0.7500000000000001] mini_distance: 25.560818361702204
episode:  11200 Evaluation Average Reward: -0.8568092241644621 avg distance 57.584499319222644 mini_state: [1.0000000000000002, 49.999999999999005, 0.44999999999999996, 0.1] mini_distance: 57.58449931922264
episode:  11300 Evaluation Average Reward: 0.17090793683058025 avg distance 49.072640921272 mini_state: [0.49999999999999994, 30.400000000000006, 0.25, 0.49999999999999994] mini_distance: 49.07264092127199
episode:  11400 Evaluation Average Reward: -0.09491015062191983 avg distance 57.81424196041371 mini_state: [0.44999999999999996, 3.4999999999997042, 0.1999999999999999, 0.049999999999999906] mini_distance: 57.81424196041371
episode:  11500 Evaluation Average Reward: 0.20429793591364281 avg distance 8.462358486729126 mini_state: [1.3877787807814457e-17, 26.44999999999995, 3.049999999999997, 1.1500000000000004] mini_distance: 8.462358486729125
episode:  11600 Evaluation Average Reward: -0.6107610307304314 avg distance 53.82997508891218 mini_state: [0.39999999999999997, 27.599999999999966, 1.3500000000000005, 1.3877787807814457e-17] mini_distance: 53.82997508891218
episode:  11700 Evaluation Average Reward: -0.5360423523682931 avg distance 56.71070183641466 mini_state: [0.25, 49.999999999999005, 0.35, 0.25] mini_distance: 56.71070183641466
episode:  11800 Evaluation Average Reward: -1.3224583656454263 avg distance 26.671938236628044 mini_state: [1.1000000000000003, 28.449999999999978, 0.0, 0.7500000000000001] mini_distance: 26.671938236628048
episode:  11900 Evaluation Average Reward: -0.05918533019333814 avg distance 57.10811590709913 mini_state: [0.44999999999999996, 3.6499999999997037, 0.0, 0.44999999999999996] mini_distance: 57.10811590709915
episode:  12000 Evaluation Average Reward: -1.792622293870719 avg distance 520.8502634415075 mini_state: [0.9000000000000002, 21.199999999999875, 0.1, 1.6500000000000008] mini_distance: 489.2063639907105
episode:  12100 Evaluation Average Reward: -0.006094948171544479 avg distance 57.817967897327875 mini_state: [0.9500000000000003, 4.7499999999997, 0.1, 1.3877787807814457e-17] mini_distance: 57.81796789732786
episode:  12200 Evaluation Average Reward: 0.3501541745991069 avg distance 57.81701099589553 mini_state: [2.499999999999999, 15.449999999999793, 0.1, 0.0] mini_distance: 57.81701099589553
episode:  12300 Evaluation Average Reward: -0.40473097033770816 avg distance 57.81750487708463 mini_state: [1.7000000000000008, 11.349999999999735, 0.1, 0.0] mini_distance: 57.81750487708463
episode:  12400 Evaluation Average Reward: -0.36719641333477804 avg distance 57.817659216453066 mini_state: [1.4500000000000006, 10.549999999999724, 0.1, 0.0] mini_distance: 57.817659216453066
episode:  12500 Evaluation Average Reward: -0.1050688653296349 avg distance 57.81738140610314 mini_state: [1.900000000000001, 12.599999999999753, 0.1, 0.0] mini_distance: 57.817381406103145
episode:  12600 Evaluation Average Reward: -0.6887256073955574 avg distance 46.033445956107904 mini_state: [1.3877787807814457e-17, 29.29999999999999, 1.7000000000000008, 0.5499999999999999] mini_distance: 46.0334459561079
episode:  12700 Evaluation Average Reward: -0.12655540788522313 avg distance 48.76045358991578 mini_state: [0.3, 29.749999999999996, 1.900000000000001, 0.1] mini_distance: 48.760453589915784
episode:  12800 Evaluation Average Reward: 0.02644326443293922 avg distance 53.884748068870024 mini_state: [0.39999999999999997, 30.300000000000004, 0.39999999999999997, 0.39999999999999997] mini_distance: 53.88474806887003
episode:  12900 Evaluation Average Reward: -0.6631009994527486 avg distance 17.67801626549007 mini_state: [1.3877787807814457e-17, 31.30000000000002, 1.2500000000000004, 0.8000000000000002] mini_distance: 17.678016265490065
episode:  13000 Evaluation Average Reward: -0.10337645785700711 avg distance 6.29400770965182 mini_state: [0.15000000000000002, 7.749999999999689, 1.3877787807814457e-17, 1.5500000000000007] mini_distance: 6.294007709651819
episode:  13100 Evaluation Average Reward: 0.015515038645030427 avg distance 19.09851903157511 mini_state: [1.5500000000000007, 49.999999999999005, 0.35, 1.0000000000000002] mini_distance: 19.09851903157511
episode:  13200 Evaluation Average Reward: -0.13546175156759688 avg distance 51.74856106734346 mini_state: [1.4500000000000006, 26.799999999999955, 1.0500000000000003, 0.049999999999999906] mini_distance: 51.74856106734345
episode:  13300 Evaluation Average Reward: -3.772659825124756 avg distance 438.8618191708397 mini_state: [1.4500000000000006, 28.54999999999998, 0.09999999999999991, 1.5000000000000007] mini_distance: 438.22579265297
episode:  13400 Evaluation Average Reward: 0.03961614953759073 avg distance 6.396570752870877 mini_state: [0.15000000000000002, 29.749999999999996, 1.2000000000000004, 1.1000000000000003] mini_distance: 6.396570752870876
episode:  13500 Evaluation Average Reward: -0.03815862876055588 avg distance 52.26212064865432 mini_state: [1.6000000000000008, 18.899999999999842, 0.25, 0.49999999999999994] mini_distance: 52.2621206486543
episode:  13600 Evaluation Average Reward: 0.00018657408316573537 avg distance 54.080074125335216 mini_state: [1.850000000000001, 21.399999999999878, 0.8500000000000001, 1.3877787807814457e-17] mini_distance: 54.080074125335216
episode:  13700 Evaluation Average Reward: -0.035323617350639665 avg distance 55.96731718520614 mini_state: [1.7500000000000009, 25.449999999999935, 0.5499999999999999, 0.3] mini_distance: 55.96731718520614
episode:  13800 Evaluation Average Reward: -0.08765531935348198 avg distance 56.7444391859069 mini_state: [2.4499999999999993, 26.54999999999995, 0.44999999999999996, 0.25] mini_distance: 56.74443918590689
episode:  13900 Evaluation Average Reward: -0.05666311900700468 avg distance 57.80173515219501 mini_state: [0.7500000000000001, 26.49999999999995, 0.1, 0.1] mini_distance: 57.80173515219501
episode:  14000 Evaluation Average Reward: -0.21926515617977546 avg distance 52.199005929494504 mini_state: [0.49999999999999994, 49.999999999999005, 1.4000000000000006, 0.1] mini_distance: 52.1990059294945
episode:  14100 Evaluation Average Reward: 0.09842877266431302 avg distance 22.116143590106617 mini_state: [0.7500000000000001, 41.44999999999949, 0.9000000000000002, 0.7000000000000001] mini_distance: 22.116143590106617
episode:  14200 Evaluation Average Reward: 0.013890485242234898 avg distance 47.38987243281081 mini_state: [0.75, 28.949999999999985, 1.4500000000000006, 0.3] mini_distance: 47.389872432810805
episode:  14300 Evaluation Average Reward: -0.29683618873355627 avg distance 57.81775182041612 mini_state: [1.3000000000000005, 9.749999999999712, 0.1, 0.0] mini_distance: 57.81775182041612
episode:  14400 Evaluation Average Reward: -0.2015770096988101 avg distance 57.55423337049889 mini_state: [0.44999999999999984, 7.54999999999969, 0.6, 1.3877787807814457e-17] mini_distance: 57.554233370498885
episode:  14500 Evaluation Average Reward: -0.004780392960054696 avg distance 22.664556382552522 mini_state: [0.75, 33.649999999999935, 2.9999999999999973, 0.049999999999999906] mini_distance: 22.664556382552526
episode:  14600 Evaluation Average Reward: -0.40299608265253534 avg distance 57.580232398522455 mini_state: [1.3877787807814457e-17, 25.74999999999994, 2.849999999999998, 0.2] mini_distance: 57.58023239852246
episode:  14700 Evaluation Average Reward: -0.2157727808329772 avg distance 53.18990341328204 mini_state: [0.49999999999999994, 11.549999999999738, 0.9000000000000001, 0.49999999999999994] mini_distance: 53.189903413282046
episode:  14800 Evaluation Average Reward: 0.02122199905726407 avg distance 52.96218058611281 mini_state: [0.10000000000000002, 26.749999999999954, 2.1000000000000005, 0.25] mini_distance: 52.962180586112815
episode:  14900 Evaluation Average Reward: 0.13008551301448892 avg distance 25.359719561372 mini_state: [0.65, 31.050000000000015, 2.0500000000000007, 0.5499999999999998] mini_distance: 25.359719561372
episode:  15000 Evaluation Average Reward: 0.0857736971186231 avg distance 37.13127342857092 mini_state: [0.7000000000000001, 27.749999999999968, 1.900000000000001, 0.3] mini_distance: 37.13127342857092
episode:  15100 Evaluation Average Reward: -0.06880913333214134 avg distance 28.468865766825623 mini_state: [0.5499999999999998, 31.050000000000015, 3.349999999999996, 1.3877787807814457e-17] mini_distance: 28.468865766825626
episode:  15200 Evaluation Average Reward: -0.12813248791020587 avg distance 57.52342508805283 mini_state: [0.39999999999999997, 30.0, 0.3, 0.2] mini_distance: 57.52342508805284
episode:  15300 Evaluation Average Reward: -0.1064974844264286 avg distance 49.71771506560085 mini_state: [0.3, 22.29999999999989, 1.4500000000000006, 0.44999999999999996] mini_distance: 49.717715065600856
episode:  15400 Evaluation Average Reward: -0.12738983540928836 avg distance 22.154253453222488 mini_state: [0.7000000000000001, 20.89999999999987, 0.8, 0.8500000000000002] mini_distance: 22.15425345322249
episode:  15500 Evaluation Average Reward: -0.3153014165251612 avg distance 224.85273639322344 mini_state: [3.649999999999995, 30.950000000000014, 1.1, 1.3500000000000005] mini_distance: 224.85273639322347
episode:  15600 Evaluation Average Reward: -0.7729769809922189 avg distance 19.31267638213453 mini_state: [2.1000000000000005, 29.749999999999996, 2.3, 0.0] mini_distance: 19.312676382134534
episode:  15700 Evaluation Average Reward: -0.04335239879327005 avg distance 55.54569689789027 mini_state: [0.7500000000000001, 29.34999999999999, 0.9500000000000003, 0.1] mini_distance: 55.54569689789027
episode:  15800 Evaluation Average Reward: 0.14457166460645288 avg distance 55.504853165292715 mini_state: [1.4000000000000006, 28.69999999999998, 0.8000000000000002, 0.1] mini_distance: 55.504853165292715
episode:  15900 Evaluation Average Reward: -0.09585620646697578 avg distance 47.5923468171768 mini_state: [1.2000000000000004, 28.899999999999984, 1.3000000000000005, 0.1] mini_distance: 47.5923468171768
episode:  16000 Evaluation Average Reward: -0.1692383056058688 avg distance 129.1625950227078 mini_state: [1.3500000000000005, 43.299999999999386, 3.099999999999997, 0.0] mini_distance: 129.16259502270776
episode:  16100 Evaluation Average Reward: -0.0067777000818229705 avg distance 65.28126318473532 mini_state: [0.049999999999999906, 22.29999999999989, 1.9000000000000008, 1.3500000000000005] mini_distance: 65.28126318473534
episode:  16200 Evaluation Average Reward: -1.4945356723467427 avg distance 478.0087336053165 mini_state: [1.9000000000000008, 34.59999999999988, 2.549999999999999, 1.2000000000000004] mini_distance: 397.28031007173286
episode:  16300 Evaluation Average Reward: -0.08377713102350534 avg distance 31.05895787616327 mini_state: [1.5500000000000007, 31.600000000000023, 2.5999999999999988, 0.35] mini_distance: 31.058957876163262
episode:  16400 Evaluation Average Reward: -0.2155586273927257 avg distance 26.533001384872186 mini_state: [1.0500000000000003, 24.34999999999992, 2.000000000000001, 1.3877787807814457e-17] mini_distance: 26.533001384872186
episode:  16500 Evaluation Average Reward: -2.1677756984878367 avg distance 19.083382739785726 mini_state: [0.15000000000000002, 29.799999999999997, 1.3877787807814457e-17, 0.8000000000000002] mini_distance: 19.08338273978573
episode:  16600 Evaluation Average Reward: -0.981314401360506 avg distance 31.48470557927238 mini_state: [0.39999999999999997, 29.699999999999996, 1.3877787807814457e-17, 0.7000000000000001] mini_distance: 31.48470557927238
a1,a2,r1,r2:[0.7500000000000001, 49.999999999999005, 0.1, 0.8500000000000002]

episode:  16700 Evaluation Average Reward: 0.07637340860490394 avg distance 0.8980686774458251 mini_state: [0.7500000000000001, 49.999999999999005, 0.1, 0.8500000000000002] mini_distance: 0.8980686774458251
[[2.8999999999999977, 32.79999999999998, 2.8999999999999977, 0.1], [2.8999999999999977, 47.199999999999164, 2.8999999999999977, 0.1], [0.2, 30.1, 0.2, 0.0], [1.5000000000000007, 29.9, 2.1000000000000005, 1.4000000000000006], [0.0, 27.549999999999965, 2.549999999999999, 0.1], [0.0, 27.499999999999964, 2.5999999999999988, 0.1], [0.1, 28.59999999999998, 1.6000000000000008, 0.0], [0.1, 28.349999999999977, 1.850000000000001, 0.0], [0.1, 30.1, 0.0, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.7000000000000001, 1.9499999999997093, 1.3877787807814457e-17, 0.1], [0.9000000000000002, 2.999999999999706, 1.3877787807814457e-17, 0.1], [1.4500000000000006, 5.049999999999699, 1.3877787807814457e-17, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.8000000000000002, 30.300000000000004, 4.049999999999994, 0.8500000000000002], [0.25, 30.150000000000002, 5.14999999999999, 1.1500000000000004], [1.7000000000000008, 6.049999999999695, 0.049999999999999906, 0.1], [0.1, 27.749999999999968, 1.7000000000000008, 1.5000000000000007], [0.1, 26.49999999999995, 2.2, 1.5000000000000007], [0.1, 30.0, 1.4500000000000006, 1.4500000000000006], [10.700000000000017, 26.299999999999947, 0.0, 0.1], [3.699999999999995, 30.70000000000001, 2.6999999999999984, 0.1], [12.650000000000045, 24.799999999999926, 0.049999999999999906, 0.1], [0.49999999999999994, 34.04999999999991, 4.6499999999999915, 0.8000000000000002], [0.49999999999999994, 33.94999999999992, 4.849999999999991, 0.49999999999999994], [0.39999999999999997, 34.349999999999895, 5.04999999999999, 0.39999999999999997], [0.35, 34.499999999999886, 5.399999999999989, 0.49999999999999994], [9.850000000000005, 26.099999999999945, 2.0500000000000007, 0.2], [0.7500000000000001, 29.29999999999999, 1.4500000000000006, 1.4500000000000006], [0.1, 31.35000000000002, 0.1, 1.4500000000000006], [0.44999999999999996, 30.0, 4.299999999999993, 1.2000000000000004], [0.2, 30.0, 0.0, 0.2], [0.1, 29.9, 0.0, 0.1], [1.4500000000000006, 30.0, 0.1, 1.4500000000000006], [0.1, 30.0, 1.4500000000000006, 1.4500000000000006], [0.1, 30.0, 0.1, 0.1], [0.0, 30.0, 0.1, 0.1], [1.900000000000001, 49.999999999999005, 0.1, 0.1], [0.0, 5.0999999999996986, 0.1, 0.1], [0.2, 4.099999999999702, 0.3, 0.0], [0.25, 4.099999999999702, 0.25, 0.0], [0.1, 5.149999999999698, 0.1, 0.1], [3.1999999999999966, 22.499999999999893, 2.799999999999998, 0.35], [0.1, 30.0, 0.1, 0.1], [4.199999999999993, 24.899999999999928, 0.8500000000000002, 1.5500000000000007], [2.9499999999999975, 25.89999999999994, 2.0500000000000007, 1.3500000000000005], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 31.45000000000002, 4.3499999999999925, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 23.899999999999913, 7.89999999999998, 0.1], [0.1, 30.0, 0.1, 0.1], [0.1, 30.0, 0.1, 0.9500000000000003], [0.1, 30.0, 0.1, 0.1], [5.14999999999999, 36.299999999999784, 1.3500000000000005, 1.3500000000000005], [5.999999999999987, 31.600000000000023, 0.1, 1.1000000000000003], [6.849999999999984, 33.19999999999996, 0.1, 1.4500000000000006], [0.1, 30.0, 0.1, 0.1], [5.649999999999988, 40.499999999999545, 2.3999999999999995, 0.1], [3.949999999999994, 37.04999999999974, 2.6499999999999986, 0.1], [1.900000000000001, 32.45, 2.1000000000000005, 0.1], [0.1, 31.000000000000014, 1.1000000000000003, 0.1], [0.6, 39.799999999999585, 3.149999999999997, 0.1], [0.1, 31.100000000000016, 1.2000000000000004, 0.1], [0.1, 30.0, 0.15000000000000002, 0.1], [1.3877787807814457e-17, 30.65000000000001, 2.0500000000000007, 0.1], [2.6999999999999984, 30.70000000000001, 2.9499999999999975, 0.1], [1.4000000000000004, 30.65000000000001, 2.1000000000000005, 0.1], [0.9000000000000002, 31.200000000000017, 1.900000000000001, 0.1], [0.7000000000000001, 29.39999999999999, 0.3, 0.1], [2.1000000000000005, 28.749999999999982, 0.0, 0.1], [2.1500000000000004, 26.59999999999995, 0.7500000000000001, 1.5000000000000007], [1.4500000000000006, 22.649999999999896, 1.5500000000000007, 1.5500000000000007], [3.4499999999999957, 19.44999999999985, 0.35, 1.6500000000000008], [0.049999999999999906, 3.599999999999704, 1.2500000000000004, 0.1], [0.049999999999999684, 29.799999999999997, 2.499999999999999, 0.39999999999999997], [0.049999999999999906, 26.899999999999956, 3.149999999999997, 0.5499999999999999], [1.3877787807814457e-17, 26.54999999999995, 3.599999999999995, 0.25], [2.4499999999999993, 29.049999999999986, 2.499999999999999, 1.2500000000000004], [2.5999999999999988, 30.65000000000001, 2.9499999999999975, 0.1], [1.0000000000000002, 9.349999999999707, 1.3877787807814457e-17, 0.1], [0.8000000000000002, 9.699999999999712, 1.3877787807814457e-17, 0.1], [1.3877787807814457e-17, 7.749999999999689, 2.3, 0.1], [1.3877787807814457e-17, 5.049999999999699, 1.3500000000000005, 0.1], [1.3877787807814457e-17, 4.6999999999997, 1.4500000000000006, 0.1], [2.1500000000000004, 15.19999999999979, 1.6000000000000008, 1.3877787807814457e-17], [2.8999999999999977, 49.999999999999005, 0.1, 0.1], [4.149999999999993, 14.249999999999776, 1.800000000000001, 0.049999999999999906], [3.899999999999994, 17.099999999999817, 1.2000000000000004, 1.7000000000000008], [3.1999999999999966, 20.74999999999987, 0.7500000000000001, 1.6000000000000008], [0.9000000000000002, 21.899999999999885, 0.25, 0.1], [0.8500000000000002, 27.699999999999967, 0.8500000000000002, 0.2], [0.3, 29.549999999999994, 0.3, 0.7500000000000001], [1.0000000000000002, 49.999999999999005, 0.44999999999999996, 0.1], [0.49999999999999994, 30.400000000000006, 0.25, 0.49999999999999994], [0.44999999999999996, 3.4999999999997042, 0.1999999999999999, 0.049999999999999906], [1.3877787807814457e-17, 26.44999999999995, 3.049999999999997, 1.1500000000000004], [0.39999999999999997, 27.599999999999966, 1.3500000000000005, 1.3877787807814457e-17], [0.25, 49.999999999999005, 0.35, 0.25], [1.1000000000000003, 28.449999999999978, 0.0, 0.7500000000000001], [0.44999999999999996, 3.6499999999997037, 0.0, 0.44999999999999996], [0.9000000000000002, 21.199999999999875, 0.1, 1.6500000000000008], [0.9500000000000003, 4.7499999999997, 0.1, 1.3877787807814457e-17], [2.499999999999999, 15.449999999999793, 0.1, 0.0], [1.7000000000000008, 11.349999999999735, 0.1, 0.0], [1.4500000000000006, 10.549999999999724, 0.1, 0.0], [1.900000000000001, 12.599999999999753, 0.1, 0.0], [1.3877787807814457e-17, 29.29999999999999, 1.7000000000000008, 0.5499999999999999], [0.3, 29.749999999999996, 1.900000000000001, 0.1], [0.39999999999999997, 30.300000000000004, 0.39999999999999997, 0.39999999999999997], [1.3877787807814457e-17, 31.30000000000002, 1.2500000000000004, 0.8000000000000002], [0.15000000000000002, 7.749999999999689, 1.3877787807814457e-17, 1.5500000000000007], [1.5500000000000007, 49.999999999999005, 0.35, 1.0000000000000002], [1.4500000000000006, 26.799999999999955, 1.0500000000000003, 0.049999999999999906], [1.4500000000000006, 28.54999999999998, 0.09999999999999991, 1.5000000000000007], [0.15000000000000002, 29.749999999999996, 1.2000000000000004, 1.1000000000000003], [1.6000000000000008, 18.899999999999842, 0.25, 0.49999999999999994], [1.850000000000001, 21.399999999999878, 0.8500000000000001, 1.3877787807814457e-17], [1.7500000000000009, 25.449999999999935, 0.5499999999999999, 0.3], [2.4499999999999993, 26.54999999999995, 0.44999999999999996, 0.25], [0.7500000000000001, 26.49999999999995, 0.1, 0.1], [0.49999999999999994, 49.999999999999005, 1.4000000000000006, 0.1], [0.7500000000000001, 41.44999999999949, 0.9000000000000002, 0.7000000000000001], [0.75, 28.949999999999985, 1.4500000000000006, 0.3], [1.3000000000000005, 9.749999999999712, 0.1, 0.0], [0.44999999999999984, 7.54999999999969, 0.6, 1.3877787807814457e-17], [0.75, 33.649999999999935, 2.9999999999999973, 0.049999999999999906], [1.3877787807814457e-17, 25.74999999999994, 2.849999999999998, 0.2], [0.49999999999999994, 11.549999999999738, 0.9000000000000001, 0.49999999999999994], [0.10000000000000002, 26.749999999999954, 2.1000000000000005, 0.25], [0.65, 31.050000000000015, 2.0500000000000007, 0.5499999999999998], [0.7000000000000001, 27.749999999999968, 1.900000000000001, 0.3], [0.5499999999999998, 31.050000000000015, 3.349999999999996, 1.3877787807814457e-17], [0.39999999999999997, 30.0, 0.3, 0.2], [0.3, 22.29999999999989, 1.4500000000000006, 0.44999999999999996], [0.7000000000000001, 20.89999999999987, 0.8, 0.8500000000000002], [3.649999999999995, 30.950000000000014, 1.1, 1.3500000000000005], [2.1000000000000005, 29.749999999999996, 2.3, 0.0], [0.7500000000000001, 29.34999999999999, 0.9500000000000003, 0.1], [1.4000000000000006, 28.69999999999998, 0.8000000000000002, 0.1], [1.2000000000000004, 28.899999999999984, 1.3000000000000005, 0.1], [1.3500000000000005, 43.299999999999386, 3.099999999999997, 0.0], [0.049999999999999906, 22.29999999999989, 1.9000000000000008, 1.3500000000000005], [1.9000000000000008, 34.59999999999988, 2.549999999999999, 1.2000000000000004], [1.5500000000000007, 31.600000000000023, 2.5999999999999988, 0.35], [1.0500000000000003, 24.34999999999992, 2.000000000000001, 1.3877787807814457e-17], [0.15000000000000002, 29.799999999999997, 1.3877787807814457e-17, 0.8000000000000002], [0.39999999999999997, 29.699999999999996, 1.3877787807814457e-17, 0.7000000000000001], [0.7500000000000001, 49.999999999999005, 0.1, 0.8500000000000002]]
[510.3709872786073, 510.3820312183885, 57.8166996206711, 427.21769307421556, 57.80155003330208, 57.80158088637957, 56.038506547639976, 54.959093701489174, 57.80002687998804, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.817702762955555, 57.81715518445024, 57.81616640989232, 57.79997656414923, 57.79997656414923, 479.1325502840116, 438.81092775280473, 57.814803332338414, 414.0456740896771, 374.0488850243637, 366.48432622377777, 57.80770583346947, 499.6085821860931, 57.8031270232206, 463.04867884078783, 546.7884965867954, 438.4909688825516, 552.4293882551764, 500.4613328022885, 364.814717819643, 409.34027624891564, 507.13887902641335, 57.542193616296956, 57.80015028666491, 361.5726922853337, 366.48432622377777, 57.79997656414923, 57.800038267424874, 57.786527972182235, 57.815405932434615, 57.80973561586252, 57.813069392410725, 57.81531333497151, 481.8132479063649, 57.79997656414923, 438.23726994273534, 362.47909826761247, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 57.79997656414923, 28.385106717812757, 57.79997656414923, 542.8432734240519, 57.79997656414923, 2.603952000273088, 57.79997656414923, 438.9499175521565, 10.788536417110821, 474.6853537715195, 57.79997656414923, 506.89835954940236, 498.67938132592764, 11.436846601202548, 57.295560961595804, 22.28226232179071, 57.12079459019098, 57.79973557596433, 57.799637198171055, 496.28492704593185, 16.44828587867774, 33.436196696717104, 57.769562789922524, 57.80186622617539, 369.7626712856416, 381.8276671502587, 389.4540005534521, 57.42584037225907, 50.330262688451704, 39.97920119310257, 57.23847994122378, 484.1080796414052, 451.77376420650387, 57.81328561237775, 57.812968932844846, 57.813770081694564, 57.81543679831262, 57.81565286025722, 26.30717421417499, 57.78591119429431, 8.005832814428404, 434.9331604410503, 354.4756850491927, 57.78530104353866, 55.83318237704722, 25.560818361702204, 57.58449931922264, 49.07264092127199, 57.81424196041371, 8.462358486729125, 53.82997508891218, 56.71070183641466, 26.671938236628048, 57.10811590709915, 489.2063639907105, 57.81796789732786, 57.81701099589553, 57.81750487708463, 57.817659216453066, 57.817381406103145, 46.0334459561079, 48.760453589915784, 53.88474806887003, 17.678016265490065, 6.294007709651819, 19.09851903157511, 51.74856106734345, 438.22579265297, 6.396570752870876, 52.2621206486543, 54.080074125335216, 55.96731718520614, 56.74443918590689, 57.80173515219501, 52.1990059294945, 22.116143590106617, 47.389872432810805, 57.81775182041612, 57.554233370498885, 22.664556382552526, 57.58023239852246, 53.189903413282046, 52.962180586112815, 25.359719561372, 37.13127342857092, 28.468865766825626, 57.52342508805284, 49.717715065600856, 22.15425345322249, 224.85273639322347, 19.312676382134534, 55.54569689789027, 55.504853165292715, 47.5923468171768, 129.16259502270776, 65.28126318473534, 397.28031007173286, 31.058957876163262, 26.533001384872186, 19.08338273978573, 31.48470557927238, 0.8980686774458251]

Process finished with exit code 0

