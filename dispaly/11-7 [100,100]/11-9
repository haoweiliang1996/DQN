/usr/bin/python3.5 /home/haowei/PycharmProjects/DQN/four.py
fig size: 80.0 DPI, size in inches [ 3.  4.]
env init ok
episode:40000,stepTimes:2400,stepSize:0.025,gbest: False,Ok_eps:1.0,init_state: [0, 100, 0, 0],agent_saved:True range: 0
start time 09--16-56
episode:  0 Evaluation Average Reward: 0.4988562091503268 avg distance 57.81855439884414 mini_state: [30.57499999999933, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
/usr/local/lib/python3.5/dist-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented
  warnings.warn(str, mplDeprecation)
episode:  100 Evaluation Average Reward: -2.0 avg distance 57.81855439884414 mini_state: [0, 100, 0, 0] mini_distance: 57.818554398844135
episode:  200 Evaluation Average Reward: 0.5005 avg distance 57.81855439884414 mini_state: [29.149999999999412, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  300 Evaluation Average Reward: 0.5043333333333333 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  400 Evaluation Average Reward: 0.5036666666666667 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  500 Evaluation Average Reward: 0.49716666666666665 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  600 Evaluation Average Reward: 0.5014583333333333 avg distance 57.81855439884414 mini_state: [15.125000000000147, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  700 Evaluation Average Reward: 0.4987083333333333 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  800 Evaluation Average Reward: 0.5020833333333333 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  900 Evaluation Average Reward: 0.4962916666666667 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  1000 Evaluation Average Reward: 0.498125 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  1100 Evaluation Average Reward: 0.5015833333333334 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  1200 Evaluation Average Reward: 0.49945833333333334 avg distance 57.81855439884414 mini_state: [29.799999999999375, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  1300 Evaluation Average Reward: 0.5005833333333334 avg distance 57.81855439884414 mini_state: [29.649999999999384, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  1400 Evaluation Average Reward: 0.49733103391639977 avg distance 508.02937534984767 mini_state: [30.39999999999934, 98.62499999999969, 0.9750000000000005, 0.9750000000000005] mini_distance: 425.3261053523082
episode:  1500 Evaluation Average Reward: 0.4992083333333333 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  1600 Evaluation Average Reward: 0.4992083333333333 avg distance 57.81855439884414 mini_state: [23.04999999999976, 136.9500000000084, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  1700 Evaluation Average Reward: 0.497 avg distance 57.81855439884414 mini_state: [8.125000000000048, 151.8750000000118, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  1800 Evaluation Average Reward: 0.4174107142857143 avg distance 489.4166760110317 mini_state: [0.0, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 351.1137087465359
episode:  1900 Evaluation Average Reward: 0.43507972665148065 avg distance 549.4362977103895 mini_state: [0.0, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 443.9545488310351
episode:  2000 Evaluation Average Reward: 0.4856548238442099 avg distance 486.90269515329845 mini_state: [6.375000000000023, 110.02500000000228, 1.0000000000000004, 1.0000000000000004] mini_distance: 409.08787390548065
episode:  2100 Evaluation Average Reward: 0.45265588914549654 avg distance 477.10706183390295 mini_state: [0.0, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 443.9545488310351
episode:  2200 Evaluation Average Reward: 0.45662100456621 avg distance 534.369320128933 mini_state: [0.0, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 443.9545488310351
episode:  2300 Evaluation Average Reward: 0.504424778761062 avg distance 499.91483157197024 mini_state: [9.00000000000006, 100.0, 1.0250000000000004, 1.0250000000000004] mini_distance: 433.2994853600112
episode:  2400 Evaluation Average Reward: 0.4528735632183908 avg distance 500.9754908283209 mini_state: [0.0, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 351.1137087465359
episode:  2500 Evaluation Average Reward: 0.49142857142857144 avg distance 500.08641262440426 mini_state: [5.025000000000004, 100.0, 1.0000000000000004, 1.0000000000000004] mini_distance: 306.5093449341777
episode:  2600 Evaluation Average Reward: 0.4877656149388281 avg distance 481.3010275073299 mini_state: [7.1750000000000345, 100.0, 1.0000000000000004, 1.0000000000000004] mini_distance: 324.76470506908294
episode:  2700 Evaluation Average Reward: 0.5082658022690437 avg distance 518.3587930500531 mini_state: [5.550000000000011, 102.50000000000057, 0.19999999999999998, 1.0500000000000003] mini_distance: 461.2865091732177
episode:  2800 Evaluation Average Reward: 0.4995 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  2900 Evaluation Average Reward: 0.5011273957158963 avg distance 503.6311716297453 mini_state: [3.349999999999992, 100.0, 0.8750000000000004, 1.0250000000000004] mini_distance: 359.8420445248779
episode:  3000 Evaluation Average Reward: 0.43935926773455375 avg distance 503.04611022123055 mini_state: [0.3, 99.44999999999987, 0.8500000000000004, 1.0500000000000003] mini_distance: 426.7061349236222
episode:  3100 Evaluation Average Reward: 0.4191343963553531 avg distance 530.9099153060124 mini_state: [0.35000000000000003, 99.74999999999994, 0.8250000000000004, 1.0500000000000003] mini_distance: 430.3063873520454
episode:  3200 Evaluation Average Reward: 0.41935483870967744 avg distance 487.3278801198733 mini_state: [0.0, 100.82500000000019, 0.1, 1.0250000000000004] mini_distance: 349.1636569305251
episode:  3300 Evaluation Average Reward: 0.48333333333333334 avg distance 554.2605631009235 mini_state: [1.2999999999999994, 100.32500000000007, 0.35000000000000003, 1.0250000000000004] mini_distance: 344.52294370067665
episode:  3400 Evaluation Average Reward: 0.5004166666666666 avg distance 57.81855439884414 mini_state: [0.0, 160.00000000001364, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  3500 Evaluation Average Reward: 0.48148148148148145 avg distance 477.23945775300433 mini_state: [1.8999999999999972, 100.8750000000002, 0.0, 1.0250000000000004] mini_distance: 348.895801204904
episode:  3600 Evaluation Average Reward: 0.4337899543378995 avg distance 509.4663759643302 mini_state: [0.0, 99.27499999999984, 0.7250000000000003, 1.0500000000000003] mini_distance: 423.00626174108527
episode:  3700 Evaluation Average Reward: 0.5 avg distance 57.81855439884414 mini_state: [0.0, 160.00000000001364, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  3800 Evaluation Average Reward: 0.49645833333333333 avg distance 57.81849072635494 mini_state: [1.5999999999999983, 158.40000000001328, 0.05, 0.0] mini_distance: 57.81849072635494
episode:  3900 Evaluation Average Reward: 0.44870283018867924 avg distance 568.3341163650305 mini_state: [5.47500000000001, 107.9250000000018, 2.3749999999999956, 0.5250000000000001] mini_distance: 499.3232216281457
episode:  4000 Evaluation Average Reward: 0.4834917458729365 avg distance 541.9789482834453 mini_state: [7.650000000000041, 109.95000000000226, 2.199999999999996, 0.1] mini_distance: 498.6727373337787
episode:  4100 Evaluation Average Reward: 0.4614528249373782 avg distance 538.3838691759263 mini_state: [6.650000000000027, 107.17500000000163, 2.274999999999996, 0.0] mini_distance: 472.91931033161086
episode:  4200 Evaluation Average Reward: 0.4985833333333333 avg distance 57.81855439884414 mini_state: [0.175, 159.8250000000136, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  4300 Evaluation Average Reward: 0.4977916666666667 avg distance 57.81855439884414 mini_state: [0.0, 89.57499999999763, 25.724999999999607, 0.0] mini_distance: 57.818554398844135
episode:  4400 Evaluation Average Reward: 0.44543650793650796 avg distance 547.7075970534411 mini_state: [1.4499999999999988, 101.45000000000033, 3.5249999999999915, 0.0] mini_distance: 497.6616386195918
episode:  4500 Evaluation Average Reward: 0.4742268041237113 avg distance 529.143661285848 mini_state: [1.2499999999999996, 96.57499999999922, 2.874999999999994, 0.9250000000000005] mini_distance: 437.71872054492746
episode:  4600 Evaluation Average Reward: 0.44204753199268737 avg distance 558.0014021775636 mini_state: [4.174999999999992, 96.79999999999927, 2.6249999999999947, 0.3] mini_distance: 533.5562867957163
episode:  4700 Evaluation Average Reward: 0.45454545454545453 avg distance 527.5244887028986 mini_state: [0.0, 98.94999999999976, 0.0, 1.0500000000000003] mini_distance: 419.2255253510821
episode:  4800 Evaluation Average Reward: 0.493125 avg distance 57.81855439884414 mini_state: [0.0, 160.00000000001364, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  4900 Evaluation Average Reward: 0.500375 avg distance 57.81855439884414 mini_state: [0.8000000000000004, 159.20000000001346, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  5000 Evaluation Average Reward: 0.47760325770796974 avg distance 504.1250284309499 mini_state: [2.0749999999999966, 98.14999999999958, 1.5749999999999984, 1.0250000000000004] mini_distance: 414.71129813033417
episode:  5100 Evaluation Average Reward: 0.47493837304847986 avg distance 564.1530254380849 mini_state: [2.774999999999994, 101.05000000000024, 1.1, 1.0500000000000003] mini_distance: 483.8300002817844
episode:  5200 Evaluation Average Reward: 0.5100869668106254 avg distance 464.93705060595255 mini_state: [1.15, 140.9000000000093, 0.7000000000000003, 0.9250000000000005] mini_distance: 327.95907415586794
episode:  5300 Evaluation Average Reward: 0.5001666666666666 avg distance 57.81855439884414 mini_state: [0.9750000000000005, 159.02500000001342, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  5400 Evaluation Average Reward: 0.47058823529411764 avg distance 484.868576013744 mini_state: [0.5500000000000002, 98.42499999999964, 0.025, 1.0500000000000003] mini_distance: 412.880040872808
episode:  5500 Evaluation Average Reward: 0.4591397849462366 avg distance 534.9842835238135 mini_state: [0.5000000000000001, 98.94999999999976, 1.125, 1.0500000000000003] mini_distance: 426.64788325331193
episode:  5600 Evaluation Average Reward: 0.5010416666666667 avg distance 57.812170374893626 mini_state: [0.4500000000000001, 160.00000000001364, 0.05, 0.05] mini_distance: 57.81217037489363
episode:  5700 Evaluation Average Reward: 0.49866666666666665 avg distance 57.81855439884414 mini_state: [1.3249999999999993, 158.67500000001334, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  5800 Evaluation Average Reward: 0.4965833333333333 avg distance 57.81855439884414 mini_state: [0.5500000000000002, 159.95000000001363, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  5900 Evaluation Average Reward: 0.501625 avg distance 57.818302147335615 mini_state: [0.025, 100.025, 0.025, 0.025] mini_distance: 57.81830214733561
episode:  6000 Evaluation Average Reward: 0.502375 avg distance 57.75675062641018 mini_state: [0.1, 100.10000000000002, 0.1, 0.1] mini_distance: 57.756750626410195
episode:  6100 Evaluation Average Reward: 0.502875 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  6200 Evaluation Average Reward: 0.4446227929373997 avg distance 565.1944562536016 mini_state: [0.6750000000000003, 99.0999999999998, 0.37500000000000006, 1.0500000000000003] mini_distance: 421.12856831015216
episode:  6300 Evaluation Average Reward: 0.43914473684210525 avg distance 511.9892093821501 mini_state: [0.47500000000000014, 99.47499999999988, 0.05, 1.0500000000000003] mini_distance: 425.13678153959233
episode:  6400 Evaluation Average Reward: 0.5013333333333333 avg distance 57.81681106987999 mini_state: [1.1749999999999998, 158.82500000001338, 0.125, 0.0] mini_distance: 57.816811069879975
episode:  6500 Evaluation Average Reward: 0.503375 avg distance 57.818302147335615 mini_state: [0.025, 100.025, 0.025, 0.025] mini_distance: 57.81830214733561
episode:  6600 Evaluation Average Reward: 0.4532828282828283 avg distance 553.6179940426898 mini_state: [0.8750000000000004, 99.24999999999983, 0.4000000000000001, 1.0750000000000002] mini_distance: 528.6316201426118
episode:  6700 Evaluation Average Reward: -3.0 avg distance 57.81855439884414 mini_state: [0, 100, 0, 0] mini_distance: 57.818554398844135
episode:  6800 Evaluation Average Reward: -4.0 avg distance 57.81855439884414 mini_state: [0, 100, 0, 0] mini_distance: 57.818554398844135
episode:  6900 Evaluation Average Reward: 0.497875 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  7000 Evaluation Average Reward: -1.0 avg distance 57.81855439884414 mini_state: [0, 100, 0, 0] mini_distance: 57.818554398844135
episode:  7100 Evaluation Average Reward: 0.45098039215686275 avg distance 39.38962912847375 mini_state: [6.938893903907228e-18, 101.3000000000003, 1.7499999999999978, 0.4500000000000001] mini_distance: 39.38962912847375
episode:  7200 Evaluation Average Reward: 0.5345454545454545 avg distance 2.3627573038732383 mini_state: [0.024999999999999953, 99.72499999999994, 1.2749999999999995, 0.7500000000000003] mini_distance: 2.3627573038732383
episode:  7300 Evaluation Average Reward: 0.5359375 avg distance 5.549585123351561 mini_state: [0.5750000000000002, 99.5499999999999, 0.024999999999999953, 0.7750000000000004] mini_distance: 5.549585123351561
episode:  7400 Evaluation Average Reward: 0.495125 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  7500 Evaluation Average Reward: 0.49666666666666665 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  7600 Evaluation Average Reward: 0.48785046728971965 avg distance 497.69535125340263 mini_state: [0.3, 100.92500000000021, 0.4250000000000001, 1.0500000000000003] mini_distance: 442.5884623173232
episode:  7700 Evaluation Average Reward: 0.4955 avg distance 57.264784804357376 mini_state: [0.37500000000000006, 84.09999999999638, 0.7750000000000004, 0.0] mini_distance: 57.26478480435737
episode:  7800 Evaluation Average Reward: 0.5016666666666667 avg distance 57.80210537975735 mini_state: [1.125, 159.00000000001342, 0.22499999999999998, 0.0] mini_distance: 57.80210537975736
episode:  7900 Evaluation Average Reward: 0.49966666666666665 avg distance 57.80173989391314 mini_state: [1.15, 159.00000000001342, 0.22499999999999998, 0.0] mini_distance: 57.80173989391315
episode:  8000 Evaluation Average Reward: 0.4972083333333333 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  8100 Evaluation Average Reward: 0.49583333333333335 avg distance 28.24774094689105 mini_state: [1.0000000000000004, 99.47499999999988, 0.024999999999999953, 0.5250000000000001] mini_distance: 28.247740946891053
episode:  8200 Evaluation Average Reward: 0.5037916666666666 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  8300 Evaluation Average Reward: 0.4498525073746313 avg distance 534.1729047893152 mini_state: [1.5499999999999985, 100.70000000000016, 0.4250000000000001, 1.0500000000000003] mini_distance: 440.4357889916324
episode:  8400 Evaluation Average Reward: 0.5010833333333333 avg distance 57.80985688542436 mini_state: [1.5749999999999984, 158.62500000001333, 0.175, 0.0] mini_distance: 57.80985688542436
episode:  8500 Evaluation Average Reward: 0.503375 avg distance 57.818246854772305 mini_state: [1.5499999999999985, 158.70000000001335, 0.07500000000000001, 0.0] mini_distance: 57.818246854772305
episode:  8600 Evaluation Average Reward: 0.5037083333333333 avg distance 57.81855439884414 mini_state: [0.07500000000000001, 99.92499999999998, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  8700 Evaluation Average Reward: 0.5002083333333334 avg distance 57.81855439884414 mini_state: [1.7999999999999976, 158.40000000001328, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  8800 Evaluation Average Reward: 0.45852534562211983 avg distance 481.5533336625982 mini_state: [0.0, 100.55000000000013, 0.0, 1.0500000000000003] mini_distance: 438.0023749222858
episode:  8900 Evaluation Average Reward: 0.47113163972286376 avg distance 472.47153559882264 mini_state: [0.0, 100.40000000000009, 0.0, 1.0250000000000004] mini_distance: 345.03783551938864
episode:  9000 Evaluation Average Reward: 0.425629290617849 avg distance 512.094301084556 mini_state: [0.0, 100.25000000000006, 0.22499999999999998, 1.0500000000000003] mini_distance: 434.450363929666
episode:  9100 Evaluation Average Reward: 0.44176706827309237 avg distance 472.8421782343965 mini_state: [0.025, 100.4250000000001, 0.0, 1.0250000000000004] mini_distance: 345.26681119456174
episode:  9200 Evaluation Average Reward: 0.5025 avg distance 57.81855042781474 mini_state: [1.5749999999999984, 158.65000000001334, 0.025, 0.0] mini_distance: 57.818550427814735
episode:  9300 Evaluation Average Reward: 0.4672395273899033 avg distance 537.5300938744837 mini_state: [1.2249999999999996, 99.04999999999978, 0.125, 1.0750000000000002] mini_distance: 525.1584143849421
episode:  9400 Evaluation Average Reward: 0.41834451901565994 avg distance 513.8857243214446 mini_state: [0.025, 100.40000000000009, 0.0, 1.0250000000000004] mini_distance: 345.0247991666681
episode:  9500 Evaluation Average Reward: 0.48452611218568664 avg distance 531.9479891611817 mini_state: [2.549999999999995, 98.87499999999974, 1.2999999999999994, 1.0500000000000003] mini_distance: 482.81775392927136
episode:  9600 Evaluation Average Reward: 0.505375 avg distance 57.57555910543006 mini_state: [0.6750000000000003, 159.22500000001347, 0.5250000000000001, 0.0] mini_distance: 57.57555910543005
episode:  9700 Evaluation Average Reward: 0.425 avg distance 548.3094977463953 mini_state: [0.15, 100.27500000000006, 0.05, 1.0500000000000003] mini_distance: 434.67775249854384
episode:  9800 Evaluation Average Reward: 0.4442508710801394 avg distance 505.1086506325174 mini_state: [0.8000000000000004, 100.47500000000011, 1.2749999999999995, 1.0250000000000004] mini_distance: 362.51047589418147
episode:  9900 Evaluation Average Reward: 0.447887323943662 avg distance 57.81820717193246 mini_state: [1.7499999999999978, 99.975, 0.07500000000000001, 0.0] mini_distance: 57.81820717193246
episode:  10000 Evaluation Average Reward: 0.4396825396825397 avg distance 57.79589240371725 mini_state: [1.5499999999999985, 100.25000000000006, 0.22499999999999998, 6.938893903907228e-18] mini_distance: 57.79589240371725
episode:  10100 Evaluation Average Reward: 0.4960821870102734 avg distance 527.8922244940612 mini_state: [27.699999999999495, 99.34999999999985, 1.0250000000000004, 0.9750000000000005] mini_distance: 455.83054271504005
episode:  10200 Evaluation Average Reward: 0.5192743764172335 avg distance 556.6257885578823 mini_state: [0.0, 100.17500000000004, 0.175, 1.0500000000000003] mini_distance: 433.56462212126974
episode:  10300 Evaluation Average Reward: 0.4618249534450652 avg distance 509.2692164871801 mini_state: [0.325, 99.89999999999998, 0.27499999999999997, 1.0500000000000003] mini_distance: 430.3265314028328
episode:  10400 Evaluation Average Reward: 0.4611872146118721 avg distance 523.8233152981492 mini_state: [0.0, 100.17500000000004, 0.07500000000000001, 1.0500000000000003] mini_distance: 433.56462212126974
episode:  10500 Evaluation Average Reward: 0.425 avg distance 554.3891879017731 mini_state: [0.025, 100.25000000000006, 0.025, 1.0250000000000004] mini_distance: 343.576550107142
episode:  10600 Evaluation Average Reward: 0.4402035623409669 avg distance 507.97961878625637 mini_state: [0.9500000000000005, 99.27499999999984, 1.0750000000000002, 1.0250000000000004] mini_distance: 345.0143137508402
episode:  10700 Evaluation Average Reward: 0.494375 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  10800 Evaluation Average Reward: 0.47544642857142855 avg distance 524.3773595151767 mini_state: [0.025, 100.07500000000002, 0.1, 1.0500000000000003] mini_distance: 432.37700795952884
episode:  10900 Evaluation Average Reward: 0.45642201834862384 avg distance 504.2798920474005 mini_state: [0.0, 100.32500000000007, 0.0, 1.0250000000000004] mini_distance: 344.3122960277068
episode:  11000 Evaluation Average Reward: 0.38018433179723504 avg distance 488.0185792171048 mini_state: [0.0, 100.4500000000001, 0.22499999999999998, 1.0000000000000004] mini_distance: 269.42135907408914
episode:  11100 Evaluation Average Reward: 0.48604651162790696 avg distance 54.82832114475168 mini_state: [0.175, 100.12500000000003, 6.938893903907228e-18, 0.8750000000000004] mini_distance: 54.82832114475169
episode:  11200 Evaluation Average Reward: 0.50425 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  11300 Evaluation Average Reward: 0.4376417233560091 avg distance 555.5903189634439 mini_state: [0.0, 100.0, 0.0, 1.0500000000000003] mini_distance: 431.50140825242613
episode:  11400 Evaluation Average Reward: 0.5036666666666667 avg distance 5.013933128994294 mini_state: [0.0, 41.074999999993125, 0.07500000000000001, 1.0000000000000004] mini_distance: 5.013933128994293
episode:  11500 Evaluation Average Reward: 0.4467120181405896 avg distance 557.4249155673426 mini_state: [0.0, 100.12500000000003, 0.0, 1.0500000000000003] mini_distance: 432.9746300133974
episode:  11600 Evaluation Average Reward: 0.3940774487471526 avg distance 531.248960703106 mini_state: [0.0, 100.07500000000002, 0.0, 1.0500000000000003] mini_distance: 432.38503985037477
episode:  11700 Evaluation Average Reward: 0.45662100456621 avg distance 520.4810801566513 mini_state: [0.0, 100.07500000000002, 0.07500000000000001, 1.0500000000000003] mini_distance: 432.38503985037477
episode:  11800 Evaluation Average Reward: 0.502 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  11900 Evaluation Average Reward: 0.49541666666666667 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 0.0, 0.0] mini_distance: 57.818554398844135
episode:  12000 Evaluation Average Reward: 0.4439359267734554 avg distance 516.5173951750494 mini_state: [0.0, 100.0, 0.0, 1.0250000000000004] mini_distance: 341.177119914731
episode:  12100 Evaluation Average Reward: 0.4091954022988506 avg distance 485.24648223596313 mini_state: [0.0, 100.0, 0.0, 1.0500000000000003] mini_distance: 431.50140825242613
episode:  12200 Evaluation Average Reward: 0.47477064220183485 avg distance 499.6619989780205 mini_state: [0.0, 100.0, 0.0, 1.0250000000000004] mini_distance: 341.177119914731
a1,a2,r1,r2:[0.1, 41.02499999999313, 0.07500000000000001, 0.9500000000000005]

episode:  12300 Evaluation Average Reward: 0.5016666666666667 avg distance 0.3546638684495081 mini_state: [0.1, 41.02499999999313, 0.07500000000000001, 0.9500000000000005] mini_distance: 0.3546638684495081
[[30.57499999999933, 100.0, 0.0, 0.0], [0, 100, 0, 0], [29.149999999999412, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [15.125000000000147, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [29.799999999999375, 100.0, 0.0, 0.0], [29.649999999999384, 100.0, 0.0, 0.0], [30.39999999999934, 98.62499999999969, 0.9750000000000005, 0.9750000000000005], [0.0, 100.0, 0.0, 0.0], [23.04999999999976, 136.9500000000084, 0.0, 0.0], [8.125000000000048, 151.8750000000118, 0.0, 0.0], [0.0, 101.02500000000023, 0.0, 1.0250000000000004], [0.0, 101.05000000000024, 0.0, 1.0500000000000003], [6.375000000000023, 110.02500000000228, 1.0000000000000004, 1.0000000000000004], [0.0, 101.05000000000024, 0.0, 1.0500000000000003], [0.0, 101.05000000000024, 0.0, 1.0500000000000003], [9.00000000000006, 100.0, 1.0250000000000004, 1.0250000000000004], [0.0, 101.02500000000023, 0.0, 1.0250000000000004], [5.025000000000004, 100.0, 1.0000000000000004, 1.0000000000000004], [7.1750000000000345, 100.0, 1.0000000000000004, 1.0000000000000004], [5.550000000000011, 102.50000000000057, 0.19999999999999998, 1.0500000000000003], [0.0, 100.0, 0.0, 0.0], [3.349999999999992, 100.0, 0.8750000000000004, 1.0250000000000004], [0.3, 99.44999999999987, 0.8500000000000004, 1.0500000000000003], [0.35000000000000003, 99.74999999999994, 0.8250000000000004, 1.0500000000000003], [0.0, 100.82500000000019, 0.1, 1.0250000000000004], [1.2999999999999994, 100.32500000000007, 0.35000000000000003, 1.0250000000000004], [0.0, 160.00000000001364, 0.0, 0.0], [1.8999999999999972, 100.8750000000002, 0.0, 1.0250000000000004], [0.0, 99.27499999999984, 0.7250000000000003, 1.0500000000000003], [0.0, 160.00000000001364, 0.0, 0.0], [1.5999999999999983, 158.40000000001328, 0.05, 0.0], [5.47500000000001, 107.9250000000018, 2.3749999999999956, 0.5250000000000001], [7.650000000000041, 109.95000000000226, 2.199999999999996, 0.1], [6.650000000000027, 107.17500000000163, 2.274999999999996, 0.0], [0.175, 159.8250000000136, 0.0, 0.0], [0.0, 89.57499999999763, 25.724999999999607, 0.0], [1.4499999999999988, 101.45000000000033, 3.5249999999999915, 0.0], [1.2499999999999996, 96.57499999999922, 2.874999999999994, 0.9250000000000005], [4.174999999999992, 96.79999999999927, 2.6249999999999947, 0.3], [0.0, 98.94999999999976, 0.0, 1.0500000000000003], [0.0, 160.00000000001364, 0.0, 0.0], [0.8000000000000004, 159.20000000001346, 0.0, 0.0], [2.0749999999999966, 98.14999999999958, 1.5749999999999984, 1.0250000000000004], [2.774999999999994, 101.05000000000024, 1.1, 1.0500000000000003], [1.15, 140.9000000000093, 0.7000000000000003, 0.9250000000000005], [0.9750000000000005, 159.02500000001342, 0.0, 0.0], [0.5500000000000002, 98.42499999999964, 0.025, 1.0500000000000003], [0.5000000000000001, 98.94999999999976, 1.125, 1.0500000000000003], [0.4500000000000001, 160.00000000001364, 0.05, 0.05], [1.3249999999999993, 158.67500000001334, 0.0, 0.0], [0.5500000000000002, 159.95000000001363, 0.0, 0.0], [0.025, 100.025, 0.025, 0.025], [0.1, 100.10000000000002, 0.1, 0.1], [0.0, 100.0, 0.0, 0.0], [0.6750000000000003, 99.0999999999998, 0.37500000000000006, 1.0500000000000003], [0.47500000000000014, 99.47499999999988, 0.05, 1.0500000000000003], [1.1749999999999998, 158.82500000001338, 0.125, 0.0], [0.025, 100.025, 0.025, 0.025], [0.8750000000000004, 99.24999999999983, 0.4000000000000001, 1.0750000000000002], [0, 100, 0, 0], [0, 100, 0, 0], [0.0, 100.0, 0.0, 0.0], [0, 100, 0, 0], [6.938893903907228e-18, 101.3000000000003, 1.7499999999999978, 0.4500000000000001], [0.024999999999999953, 99.72499999999994, 1.2749999999999995, 0.7500000000000003], [0.5750000000000002, 99.5499999999999, 0.024999999999999953, 0.7750000000000004], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [0.3, 100.92500000000021, 0.4250000000000001, 1.0500000000000003], [0.37500000000000006, 84.09999999999638, 0.7750000000000004, 0.0], [1.125, 159.00000000001342, 0.22499999999999998, 0.0], [1.15, 159.00000000001342, 0.22499999999999998, 0.0], [0.0, 100.0, 0.0, 0.0], [1.0000000000000004, 99.47499999999988, 0.024999999999999953, 0.5250000000000001], [0.0, 100.0, 0.0, 0.0], [1.5499999999999985, 100.70000000000016, 0.4250000000000001, 1.0500000000000003], [1.5749999999999984, 158.62500000001333, 0.175, 0.0], [1.5499999999999985, 158.70000000001335, 0.07500000000000001, 0.0], [0.07500000000000001, 99.92499999999998, 0.0, 0.0], [1.7999999999999976, 158.40000000001328, 0.0, 0.0], [0.0, 100.55000000000013, 0.0, 1.0500000000000003], [0.0, 100.40000000000009, 0.0, 1.0250000000000004], [0.0, 100.25000000000006, 0.22499999999999998, 1.0500000000000003], [0.025, 100.4250000000001, 0.0, 1.0250000000000004], [1.5749999999999984, 158.65000000001334, 0.025, 0.0], [1.2249999999999996, 99.04999999999978, 0.125, 1.0750000000000002], [0.025, 100.40000000000009, 0.0, 1.0250000000000004], [2.549999999999995, 98.87499999999974, 1.2999999999999994, 1.0500000000000003], [0.6750000000000003, 159.22500000001347, 0.5250000000000001, 0.0], [0.15, 100.27500000000006, 0.05, 1.0500000000000003], [0.8000000000000004, 100.47500000000011, 1.2749999999999995, 1.0250000000000004], [1.7499999999999978, 99.975, 0.07500000000000001, 0.0], [1.5499999999999985, 100.25000000000006, 0.22499999999999998, 6.938893903907228e-18], [27.699999999999495, 99.34999999999985, 1.0250000000000004, 0.9750000000000005], [0.0, 100.17500000000004, 0.175, 1.0500000000000003], [0.325, 99.89999999999998, 0.27499999999999997, 1.0500000000000003], [0.0, 100.17500000000004, 0.07500000000000001, 1.0500000000000003], [0.025, 100.25000000000006, 0.025, 1.0250000000000004], [0.9500000000000005, 99.27499999999984, 1.0750000000000002, 1.0250000000000004], [0.0, 100.0, 0.0, 0.0], [0.025, 100.07500000000002, 0.1, 1.0500000000000003], [0.0, 100.32500000000007, 0.0, 1.0250000000000004], [0.0, 100.4500000000001, 0.22499999999999998, 1.0000000000000004], [0.175, 100.12500000000003, 6.938893903907228e-18, 0.8750000000000004], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 1.0500000000000003], [0.0, 41.074999999993125, 0.07500000000000001, 1.0000000000000004], [0.0, 100.12500000000003, 0.0, 1.0500000000000003], [0.0, 100.07500000000002, 0.0, 1.0500000000000003], [0.0, 100.07500000000002, 0.07500000000000001, 1.0500000000000003], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 0.0], [0.0, 100.0, 0.0, 1.0250000000000004], [0.0, 100.0, 0.0, 1.0500000000000003], [0.0, 100.0, 0.0, 1.0250000000000004], [0.1, 41.02499999999313, 0.07500000000000001, 0.9500000000000005]]
[57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 425.3261053523082, 57.818554398844135, 57.818554398844135, 57.818554398844135, 351.1137087465359, 443.9545488310351, 409.08787390548065, 443.9545488310351, 443.9545488310351, 433.2994853600112, 351.1137087465359, 306.5093449341777, 324.76470506908294, 461.2865091732177, 57.818554398844135, 359.8420445248779, 426.7061349236222, 430.3063873520454, 349.1636569305251, 344.52294370067665, 57.818554398844135, 348.895801204904, 423.00626174108527, 57.818554398844135, 57.81849072635494, 499.3232216281457, 498.6727373337787, 472.91931033161086, 57.818554398844135, 57.818554398844135, 497.6616386195918, 437.71872054492746, 533.5562867957163, 419.2255253510821, 57.818554398844135, 57.818554398844135, 414.71129813033417, 483.8300002817844, 327.95907415586794, 57.818554398844135, 412.880040872808, 426.64788325331193, 57.81217037489363, 57.818554398844135, 57.818554398844135, 57.81830214733561, 57.756750626410195, 57.818554398844135, 421.12856831015216, 425.13678153959233, 57.816811069879975, 57.81830214733561, 528.6316201426118, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 39.38962912847375, 2.3627573038732383, 5.549585123351561, 57.818554398844135, 57.818554398844135, 442.5884623173232, 57.26478480435737, 57.80210537975736, 57.80173989391315, 57.818554398844135, 28.247740946891053, 57.818554398844135, 440.4357889916324, 57.80985688542436, 57.818246854772305, 57.818554398844135, 57.818554398844135, 438.0023749222858, 345.03783551938864, 434.450363929666, 345.26681119456174, 57.818550427814735, 525.1584143849421, 345.0247991666681, 482.81775392927136, 57.57555910543005, 434.67775249854384, 362.51047589418147, 57.81820717193246, 57.79589240371725, 455.83054271504005, 433.56462212126974, 430.3265314028328, 433.56462212126974, 343.576550107142, 345.0143137508402, 57.818554398844135, 432.37700795952884, 344.3122960277068, 269.42135907408914, 54.82832114475169, 57.818554398844135, 431.50140825242613, 5.013933128994293, 432.9746300133974, 432.38503985037477, 432.38503985037477, 57.818554398844135, 57.818554398844135, 341.177119914731, 431.50140825242613, 341.177119914731, 0.3546638684495081]
over time 09--17-37

Process finished with exit code 0
