/usr/bin/python3.5 /home/haowei/PycharmProjects/DQN/four.py
fig size: 80.0 DPI, size in inches [ 3.  4.]
env init ok
episode:40000,stepTimes:2400,stepSize:0.025,gbest: False,Ok_eps:1.0,init_state: [0, 100, 0, 0],agent_saved:True range: 0
start time 08--00-23
episode:  0 Evaluation Average Reward: -104.11483887364628 avg distance 57.81855439884414 mini_state: [0, 100, 0, 0] mini_distance: 57.818554398844135
/usr/local/lib/python3.5/dist-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented
  warnings.warn(str, mplDeprecation)
episode:  100 Evaluation Average Reward: -90.3065555727499 avg distance 57.81855439884414 mini_state: [0, 100, 0, 0] mini_distance: 57.818554398844135
episode:  200 Evaluation Average Reward: -0.8542991080959736 avg distance 566.2855675289114 mini_state: [2.874999999999994, 100.0, 2.9249999999999936, 0.0] mini_distance: 538.31721776446
episode:  300 Evaluation Average Reward: -0.2527796430966951 avg distance 525.7423898091305 mini_state: [25.399999999999626, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 479.2461524525502
episode:  400 Evaluation Average Reward: -0.2908375514646427 avg distance 524.8742502639255 mini_state: [24.674999999999667, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 379.46537885373186
episode:  500 Evaluation Average Reward: -1.0671273960218917 avg distance 498.2015943337231 mini_state: [19.749999999999947, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 367.19816592912764
episode:  600 Evaluation Average Reward: -2.013101002881312 avg distance 488.63557281771256 mini_state: [5.600000000000012, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 350.29085633149634
episode:  700 Evaluation Average Reward: -1.7772689906869445 avg distance 488.5687454978871 mini_state: [5.300000000000008, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 350.2269142540333
episode:  800 Evaluation Average Reward: -2.7420896881509442 avg distance 488.53196163776227 mini_state: [5.100000000000005, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 350.19108013049714
episode:  900 Evaluation Average Reward: -2.211420232727441 avg distance 523.8056472902499 mini_state: [5.0000000000000036, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 442.6986325991824
episode:  1000 Evaluation Average Reward: -3.3189198439083145 avg distance 499.7151951154381 mini_state: [4.449999999999996, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 442.63994962069904
episode:  1100 Evaluation Average Reward: -3.7113862894524505 avg distance 591.845354217311 mini_state: [4.599999999999998, 101.07500000000024, 0.0, 1.0750000000000002] mini_distance: 552.7952206409094
episode:  1200 Evaluation Average Reward: -2.2944216432416105 avg distance 499.4758725034464 mini_state: [4.4999999999999964, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 350.11618861477746
episode:  1300 Evaluation Average Reward: -1.710969587585461 avg distance 521.740607349089 mini_state: [4.349999999999994, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 442.63450744265066
episode:  1400 Evaluation Average Reward: -3.416191275992269 avg distance 510.7312495639368 mini_state: [4.449999999999996, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 442.63994962069904
episode:  1500 Evaluation Average Reward: -3.0367192186017045 avg distance 466.4260367229872 mini_state: [4.349999999999994, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 350.10510890496556
episode:  1600 Evaluation Average Reward: -3.4258861452008804 avg distance 499.47032694485625 mini_state: [4.349999999999994, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 350.10510890496556
episode:  1700 Evaluation Average Reward: -4.4192153130345595 avg distance 541.8063199259548 mini_state: [4.875000000000002, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 442.6810231199256
episode:  1800 Evaluation Average Reward: -2.238181682059304 avg distance 502.79639522722255 mini_state: [4.950000000000003, 101.00000000000023, 1.3249999999999993, 1.0000000000000004] mini_distance: 387.46842730929427
episode:  1900 Evaluation Average Reward: -2.7118392430169957 avg distance 545.8894126800063 mini_state: [5.3500000000000085, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 442.7613093610473
episode:  2000 Evaluation Average Reward: -2.5431695181247567 avg distance 547.7227802326265 mini_state: [5.675000000000013, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 350.308752643139
episode:  2100 Evaluation Average Reward: -1.0053852804135859 avg distance 498.2282586657595 mini_state: [6.600000000000026, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 443.14599969006787
episode:  2200 Evaluation Average Reward: -1.4018610195079617 avg distance 522.3042354812799 mini_state: [7.200000000000035, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 350.83841615895096
episode:  2300 Evaluation Average Reward: -1.8290948972061123 avg distance 501.7277867902153 mini_state: [7.150000000000034, 101.02500000000023, 0.7500000000000003, 1.0250000000000004] mini_distance: 374.4143914117521
episode:  2400 Evaluation Average Reward: -1.2303010558625274 avg distance 538.5822575218468 mini_state: [6.800000000000029, 100.0, 2.274999999999996, 0.0] mini_distance: 500.59509863883153
episode:  2500 Evaluation Average Reward: -1.7249181576653718 avg distance 566.1383808122778 mini_state: [2.774999999999994, 100.0, 2.9499999999999935, 0.0] mini_distance: 531.0994781991552
episode:  2600 Evaluation Average Reward: -1.321516539224802 avg distance 539.3670840763876 mini_state: [6.100000000000019, 100.0, 2.3499999999999956, 0.0] mini_distance: 509.2234458138069
episode:  2700 Evaluation Average Reward: -0.573052083823192 avg distance 550.2305231532209 mini_state: [4.624999999999998, 100.0, 2.549999999999995, 0.0] mini_distance: 526.3108333896698
episode:  2800 Evaluation Average Reward: -1.6056638152481495 avg distance 557.5739850891416 mini_state: [6.87500000000003, 97.72499999999948, 2.274999999999996, 0.0] mini_distance: 514.7359588223131
episode:  2900 Evaluation Average Reward: -10.565034956712745 avg distance 493.59225149343575 mini_state: [1.0500000000000003, 98.94999999999976, 0.0, 1.0500000000000003] mini_distance: 418.6459606386812
episode:  3000 Evaluation Average Reward: -0.4895129546547831 avg distance 535.9907734323391 mini_state: [3.4749999999999917, 97.27499999999938, 2.7249999999999943, 0.0] mini_distance: 463.24358333776706
episode:  3100 Evaluation Average Reward: -0.4295609494847871 avg distance 556.4501964174958 mini_state: [2.9749999999999934, 97.12499999999935, 2.874999999999994, 0.0] mini_distance: 504.1220844504075
episode:  3200 Evaluation Average Reward: -1.4121029104888458 avg distance 552.0128726990303 mini_state: [2.7499999999999942, 96.9249999999993, 2.9249999999999936, 0.0] mini_distance: 482.1731634365282
episode:  3300 Evaluation Average Reward: -1.3358477471956387 avg distance 563.5873766812482 mini_state: [2.824999999999994, 97.07499999999933, 2.9249999999999936, 0.0] mini_distance: 515.4750199449796
episode:  3400 Evaluation Average Reward: -0.91624190639689 avg distance 562.0980389755135 mini_state: [3.2749999999999924, 97.19999999999936, 2.799999999999994, 0.0] mini_distance: 507.7238918818809
episode:  3500 Evaluation Average Reward: -0.9915736414038473 avg distance 560.1963953305102 mini_state: [3.4499999999999917, 97.22499999999937, 2.774999999999994, 0.0] mini_distance: 534.1357792230261
episode:  3600 Evaluation Average Reward: -0.7257193852411284 avg distance 539.9292378834691 mini_state: [2.9749999999999934, 86.29999999999688, 2.874999999999994, 0.0] mini_distance: 504.1220844504075
episode:  3700 Evaluation Average Reward: -0.39573380336838787 avg distance 568.410802141221 mini_state: [3.074999999999993, 83.54999999999626, 2.874999999999994, 0.0] mini_distance: 547.1240681047593
episode:  3800 Evaluation Average Reward: -0.9961950464898957 avg distance 539.2544507352932 mini_state: [3.4499999999999917, 97.24999999999937, 2.7499999999999942, 0.0] mini_distance: 493.28553735839614
episode:  3900 Evaluation Average Reward: -1.3906994686458864 avg distance 550.2656930972589 mini_state: [3.649999999999991, 97.27499999999938, 2.7249999999999943, 0.0] mini_distance: 523.8278004608779
episode:  4000 Evaluation Average Reward: -14.46584879612224 avg distance 525.0852361204832 mini_state: [0.0, 101.02500000000023, 1.0250000000000004, 1.0250000000000004] mini_distance: 351.1137087465359
episode:  4100 Evaluation Average Reward: -1.0720708790133697 avg distance 539.262662397203 mini_state: [3.5749999999999913, 97.27499999999938, 2.7249999999999943, 0.0] mini_distance: 497.3915062808927
episode:  4200 Evaluation Average Reward: -0.17244860652693247 avg distance 541.2680758941299 mini_state: [3.649999999999991, 97.27499999999938, 2.7249999999999943, 0.0] mini_distance: 523.8278004608779
episode:  4300 Evaluation Average Reward: -14.130459523781688 avg distance 547.4282277534727 mini_state: [0.0, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 443.9545488310351
episode:  4400 Evaluation Average Reward: -16.28850630463556 avg distance 560.4871353780121 mini_state: [0.0, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 443.9545488310351
episode:  4500 Evaluation Average Reward: -15.548190114863639 avg distance 529.101376034317 mini_state: [0.0, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 351.1137087465359
episode:  4600 Evaluation Average Reward: -14.551820085299639 avg distance 474.49746743925573 mini_state: [0.0, 100.0, 0.0, 1.0500000000000003] mini_distance: 431.50140825242613
episode:  4700 Evaluation Average Reward: -14.005191927666603 avg distance 497.94541301508264 mini_state: [0.0, 100.0, 0.0, 1.0500000000000003] mini_distance: 431.50140825242613
episode:  4800 Evaluation Average Reward: -14.551784589790861 avg distance 553.6404029810317 mini_state: [0.0, 100.0, 0.0, 1.0500000000000003] mini_distance: 431.50140825242613
episode:  4900 Evaluation Average Reward: -15.727011361064559 avg distance 523.3432745733217 mini_state: [0.0, 100.0, 0.0, 1.0500000000000003] mini_distance: 431.50140825242613
episode:  5000 Evaluation Average Reward: -16.096924148521364 avg distance 485.24648223596313 mini_state: [0.0, 100.0, 0.0, 1.0500000000000003] mini_distance: 431.50140825242613
episode:  5100 Evaluation Average Reward: -8.514889541617846 avg distance 551.6904869986196 mini_state: [0.0, 100.0, 0.0, 1.0750000000000002] mini_distance: 538.9915562195001
episode:  5200 Evaluation Average Reward: -16.742240010003 avg distance 478.16396938460576 mini_state: [0.0, 100.0, 0.0, 1.0250000000000004] mini_distance: 341.177119914731
episode:  5300 Evaluation Average Reward: -14.585010953259536 avg distance 499.66199897802045 mini_state: [0.0, 100.0, 0.0, 1.0250000000000004] mini_distance: 341.177119914731
episode:  5400 Evaluation Average Reward: -16.33728790030256 avg distance 521.3933585909097 mini_state: [0.0, 100.0, 0.0, 1.0500000000000003] mini_distance: 431.50140825242613
episode:  5500 Evaluation Average Reward: -19.270471730020002 avg distance 546.5578901296743 mini_state: [0.0, 100.0, 0.0, 1.0250000000000004] mini_distance: 341.177119914731
episode:  5600 Evaluation Average Reward: -18.344269681229523 avg distance 517.4935266260853 mini_state: [0.0, 100.0, 0.0, 1.0500000000000003] mini_distance: 431.50140825242613
episode:  5700 Evaluation Average Reward: -8.957168095485464 avg distance 523.3184824613104 mini_state: [0.0, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 443.9545488310351
episode:  5800 Evaluation Average Reward: -19.214932549484477 avg distance 488.15789950152555 mini_state: [0.0, 101.05000000000024, 0.0, 1.0500000000000003] mini_distance: 443.9545488310351
episode:  5900 Evaluation Average Reward: -14.300715417072484 avg distance 527.0933060774 mini_state: [0.0, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 351.1137087465359
episode:  6000 Evaluation Average Reward: -22.442702680679623 avg distance 517.8092220689502 mini_state: [0.0, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 351.1137087465359
episode:  6100 Evaluation Average Reward: -7.675904924352299 avg distance 512.0263284959435 mini_state: [0.0, 101.02500000000023, 0.0, 1.0250000000000004] mini_distance: 351.1137087465359
episode:  6200 Evaluation Average Reward: -1.7688760061736275 avg distance 548.521559248011 mini_state: [2.1249999999999964, 96.82499999999928, 3.1749999999999927, 0.0] mini_distance: 519.4519385776545
episode:  6300 Evaluation Average Reward: -9.305795752497133 avg distance 513.1001693868736 mini_state: [1.8749999999999973, 100.12500000000003, 1.8749999999999973, 1.0000000000000004] mini_distance: 407.65003120988405
episode:  6400 Evaluation Average Reward: -5.605953314633729 avg distance 502.08297418502406 mini_state: [2.8999999999999937, 99.19999999999982, 1.7749999999999977, 0.9750000000000005] mini_distance: 363.10883817021045
episode:  6500 Evaluation Average Reward: -0.13313899294418147 avg distance 53.510488274460045 mini_state: [2.6499999999999946, 156.55000000001286, 0.8000000000000004, 0.0] mini_distance: 53.510488274460045
episode:  6600 Evaluation Average Reward: -0.058697358618651795 avg distance 55.36752723676089 mini_state: [2.1249999999999964, 157.150000000013, 0.7250000000000003, 0.0] mini_distance: 55.3675272367609
episode:  6700 Evaluation Average Reward: -0.10134010883966586 avg distance 56.78293479644479 mini_state: [1.5249999999999986, 157.85000000001315, 0.6250000000000002, 0.0] mini_distance: 56.78293479644479
episode:  6800 Evaluation Average Reward: -0.983427627104554 avg distance 559.5017530822399 mini_state: [1.5749999999999984, 101.82500000000041, 3.4749999999999917, 0.0] mini_distance: 539.3653124430512
episode:  6900 Evaluation Average Reward: -0.00849612212180046 avg distance 54.94936176765761 mini_state: [0.8000000000000004, 158.20000000001323, 1.0000000000000004, 0.0] mini_distance: 54.949361767657614
episode:  7000 Evaluation Average Reward: -0.01206945906452931 avg distance 556.6202558921581 mini_state: [0.7000000000000003, 102.67500000000061, 4.399999999999995, 0.0] mini_distance: 541.3387813093543
episode:  7100 Evaluation Average Reward: -0.11119443207938506 avg distance 56.1286150285389 mini_state: [0.1, 158.32500000001326, 1.5749999999999984, 0.0] mini_distance: 56.128615028538896
episode:  7200 Evaluation Average Reward: -0.005770344767857547 avg distance 56.380736023550824 mini_state: [0.1, 158.40000000001328, 1.4999999999999987, 0.0] mini_distance: 56.38073602355082
episode:  7300 Evaluation Average Reward: -0.05342322238000587 avg distance 56.70661555131268 mini_state: [0.125, 158.57500000001332, 1.2999999999999994, 0.0] mini_distance: 56.70661555131267
episode:  7400 Evaluation Average Reward: 0.1891300710363231 avg distance 54.42079319576591 mini_state: [0.15, 158.12500000001322, 1.7249999999999979, 0.0] mini_distance: 54.42079319576591
episode:  7500 Evaluation Average Reward: -44.34336477299761 avg distance 57.81855439884414 mini_state: [0.0, 100.0, 49.949999999998234, 0.0] mini_distance: 57.818554398844135
episode:  7600 Evaluation Average Reward: -74.93915560190584 avg distance 57.81855439884414 mini_state: [0.0, 110.00000000000227, 54.57499999999797, 0.0] mini_distance: 57.818554398844135
episode:  7700 Evaluation Average Reward: -80.1317124821265 avg distance 57.81855439884414 mini_state: [0.0, 106.72500000000153, 52.79999999999807, 0.0] mini_distance: 57.818554398844135
episode:  7800 Evaluation Average Reward: -74.87308129198422 avg distance 57.81855439884414 mini_state: [0.0, 108.17500000000186, 53.34999999999804, 0.0] mini_distance: 57.818554398844135
episode:  7900 Evaluation Average Reward: -0.7263690210841778 avg distance 572.4287967026806 mini_state: [0.025, 106.47500000000147, 12.225000000000106, 0.0] mini_distance: 560.6918736290595
episode:  8000 Evaluation Average Reward: 0.0833691538898013 avg distance 573.8370315457905 mini_state: [0.07500000000000001, 104.20000000000095, 8.650000000000055, 0.0] mini_distance: 550.8369229129776
episode:  8100 Evaluation Average Reward: -50.810839299575754 avg distance 57.81855439884414 mini_state: [0.0, 103.72500000000085, 51.12499999999817, 0.0] mini_distance: 57.818554398844135
episode:  8200 Evaluation Average Reward: -0.13166392470869523 avg distance 52.39641353302629 mini_state: [1.1, 160.00000000001364, 1.1, 0.0] mini_distance: 52.3964135330263
episode:  8300 Evaluation Average Reward: -0.03814719754345049 avg distance 57.67216553135212 mini_state: [1.8499999999999974, 158.5000000000133, 0.35000000000000003, 0.0] mini_distance: 57.672165531352114
episode:  8400 Evaluation Average Reward: 0.0874833006895426 avg distance 54.53662118322028 mini_state: [1.3249999999999993, 159.57500000001355, 0.9000000000000005, 0.0] mini_distance: 54.53662118322026
episode:  8500 Evaluation Average Reward: 0.012616155006408997 avg distance 50.922391067050306 mini_state: [1.5249999999999986, 159.55000000001354, 1.0750000000000002, 0.0] mini_distance: 50.92239106705031
episode:  8600 Evaluation Average Reward: 0.021732132997961805 avg distance 51.637174724826465 mini_state: [1.7499999999999978, 159.25000000001347, 1.0000000000000004, 0.0] mini_distance: 51.63717472482646
episode:  8700 Evaluation Average Reward: -1.0914173889491212 avg distance 567.178352809108 mini_state: [1.7499999999999978, 100.9000000000002, 3.349999999999992, 0.4500000000000001] mini_distance: 542.8449426663901
episode:  8800 Evaluation Average Reward: -1.5034526427760184 avg distance 551.9375656794869 mini_state: [2.0749999999999966, 100.82500000000019, 3.049999999999993, 0.6750000000000003] mini_distance: 506.1976137889279
episode:  8900 Evaluation Average Reward: -1.363102623180935 avg distance 575.5354910300463 mini_state: [2.0749999999999966, 100.72500000000016, 3.124999999999993, 0.5750000000000002] mini_distance: 512.9820504231471
episode:  9000 Evaluation Average Reward: -1.2882107783872327 avg distance 572.0922890163922 mini_state: [2.1249999999999964, 100.65000000000015, 3.099999999999993, 0.6250000000000002] mini_distance: 547.339785615097
episode:  9100 Evaluation Average Reward: -0.9649595481802165 avg distance 569.0021264625656 mini_state: [2.199999999999996, 100.80000000000018, 3.099999999999993, 0.5750000000000002] mini_distance: 550.7435766535827
episode:  9200 Evaluation Average Reward: -2.242075097603734 avg distance 535.6640332124261 mini_state: [2.3749999999999956, 100.67500000000015, 2.799999999999994, 0.7500000000000003] mini_distance: 449.93619497678384
episode:  9300 Evaluation Average Reward: -1.1606157987328762 avg distance 534.6668200514293 mini_state: [2.4249999999999954, 100.77500000000018, 2.7249999999999943, 0.8000000000000004] mini_distance: 475.6267329804123
episode:  9400 Evaluation Average Reward: -6.296860429975292 avg distance 493.6664779394805 mini_state: [2.3499999999999956, 100.80000000000018, 2.024999999999997, 0.9750000000000005] mini_distance: 429.21235929521725
episode:  9500 Evaluation Average Reward: -2.2135795706583696 avg distance 542.1608933107067 mini_state: [2.224999999999996, 100.80000000000018, 2.799999999999994, 0.8000000000000004] mini_distance: 481.3279021003127
episode:  9600 Evaluation Average Reward: -2.491073462964175 avg distance 521.5215349037926 mini_state: [1.974999999999997, 100.92500000000021, 3.0249999999999932, 0.7250000000000003] mini_distance: 489.2251116466292
episode:  9700 Evaluation Average Reward: -1.3395884224394865 avg distance 553.5947151543689 mini_state: [2.299999999999996, 100.75000000000017, 2.9499999999999935, 0.7000000000000003] mini_distance: 523.5101121649168
episode:  9800 Evaluation Average Reward: -4.499770282610133 avg distance 521.4710911084015 mini_state: [2.4249999999999954, 100.9000000000002, 2.3499999999999956, 0.9250000000000005] mini_distance: 463.2317245806367
episode:  9900 Evaluation Average Reward: -3.236244438182642 avg distance 534.0931796215282 mini_state: [2.1749999999999963, 101.12500000000026, 2.6249999999999947, 0.8750000000000004] mini_distance: 473.1234041126976
episode:  10000 Evaluation Average Reward: -10.422011483654114 avg distance 521.953672608072 mini_state: [2.274999999999996, 101.15000000000026, 1.15, 1.0250000000000004] mini_distance: 386.3787859675938
episode:  10100 Evaluation Average Reward: -9.333834611848037 avg distance 499.38578401728967 mini_state: [2.274999999999996, 101.12500000000026, 1.125, 1.0000000000000004] mini_distance: 302.6033275267504
episode:  10200 Evaluation Average Reward: -0.683416161725432 avg distance 533.2070654794114 mini_state: [1.8249999999999975, 94.47499999999874, 3.149999999999993, 0.6750000000000003] mini_distance: 475.69343940414933
episode:  10300 Evaluation Average Reward: -4.710613103704028 avg distance 517.982263235165 mini_state: [0.9750000000000005, 99.975, 3.1749999999999927, 0.9000000000000005] mini_distance: 435.3973742203867
episode:  10400 Evaluation Average Reward: -0.06635588029523698 avg distance 563.683825442011 mini_state: [0.7250000000000003, 55.39999999999231, 4.349999999999994, 0.4250000000000001] mini_distance: 548.016721318525
episode:  10500 Evaluation Average Reward: -0.037080131482582046 avg distance 44.21540678501437 mini_state: [0.5000000000000001, 40.199999999993175, 0.5000000000000001, 0.5250000000000001] mini_distance: 44.21540678501438
episode:  10600 Evaluation Average Reward: 0.05382889808293185 avg distance 52.4045577281734 mini_state: [0.5750000000000002, 40.39999999999316, 0.5750000000000002, 0.4000000000000001] mini_distance: 52.404557728173394
episode:  10700 Evaluation Average Reward: 0.022884199101576668 avg distance 3.014919035876123 mini_state: [26.57499999999956, 40.79999999999314, 0.9250000000000005, 0.8000000000000004] mini_distance: 3.0149190358761233
episode:  10800 Evaluation Average Reward: -0.054373198182333916 avg distance 375.28045673736653 mini_state: [19.84999999999994, 40.82499999999314, 1.5499999999999985, 0.8250000000000004] mini_distance: 375.2804567373666
a1,a2,r1,r2:[0.3, 40.94999999999313, 0.3, 0.9500000000000005]

episode:  10900 Evaluation Average Reward: -0.1402968578674957 avg distance 0.3387201335915563 mini_state: [0.3, 40.94999999999313, 0.3, 0.9500000000000005] mini_distance: 0.3387201335915563
[[0, 100, 0, 0], [0, 100, 0, 0], [2.874999999999994, 100.0, 2.9249999999999936, 0.0], [25.399999999999626, 101.05000000000024, 0.0, 1.0500000000000003], [24.674999999999667, 101.02500000000023, 0.0, 1.0250000000000004], [19.749999999999947, 101.02500000000023, 0.0, 1.0250000000000004], [5.600000000000012, 101.02500000000023, 0.0, 1.0250000000000004], [5.300000000000008, 101.02500000000023, 0.0, 1.0250000000000004], [5.100000000000005, 101.02500000000023, 0.0, 1.0250000000000004], [5.0000000000000036, 101.05000000000024, 0.0, 1.0500000000000003], [4.449999999999996, 101.05000000000024, 0.0, 1.0500000000000003], [4.599999999999998, 101.07500000000024, 0.0, 1.0750000000000002], [4.4999999999999964, 101.02500000000023, 0.0, 1.0250000000000004], [4.349999999999994, 101.05000000000024, 0.0, 1.0500000000000003], [4.449999999999996, 101.05000000000024, 0.0, 1.0500000000000003], [4.349999999999994, 101.02500000000023, 0.0, 1.0250000000000004], [4.349999999999994, 101.02500000000023, 0.0, 1.0250000000000004], [4.875000000000002, 101.05000000000024, 0.0, 1.0500000000000003], [4.950000000000003, 101.00000000000023, 1.3249999999999993, 1.0000000000000004], [5.3500000000000085, 101.05000000000024, 0.0, 1.0500000000000003], [5.675000000000013, 101.02500000000023, 0.0, 1.0250000000000004], [6.600000000000026, 101.05000000000024, 0.0, 1.0500000000000003], [7.200000000000035, 101.02500000000023, 0.0, 1.0250000000000004], [7.150000000000034, 101.02500000000023, 0.7500000000000003, 1.0250000000000004], [6.800000000000029, 100.0, 2.274999999999996, 0.0], [2.774999999999994, 100.0, 2.9499999999999935, 0.0], [6.100000000000019, 100.0, 2.3499999999999956, 0.0], [4.624999999999998, 100.0, 2.549999999999995, 0.0], [6.87500000000003, 97.72499999999948, 2.274999999999996, 0.0], [1.0500000000000003, 98.94999999999976, 0.0, 1.0500000000000003], [3.4749999999999917, 97.27499999999938, 2.7249999999999943, 0.0], [2.9749999999999934, 97.12499999999935, 2.874999999999994, 0.0], [2.7499999999999942, 96.9249999999993, 2.9249999999999936, 0.0], [2.824999999999994, 97.07499999999933, 2.9249999999999936, 0.0], [3.2749999999999924, 97.19999999999936, 2.799999999999994, 0.0], [3.4499999999999917, 97.22499999999937, 2.774999999999994, 0.0], [2.9749999999999934, 86.29999999999688, 2.874999999999994, 0.0], [3.074999999999993, 83.54999999999626, 2.874999999999994, 0.0], [3.4499999999999917, 97.24999999999937, 2.7499999999999942, 0.0], [3.649999999999991, 97.27499999999938, 2.7249999999999943, 0.0], [0.0, 101.02500000000023, 1.0250000000000004, 1.0250000000000004], [3.5749999999999913, 97.27499999999938, 2.7249999999999943, 0.0], [3.649999999999991, 97.27499999999938, 2.7249999999999943, 0.0], [0.0, 101.05000000000024, 0.0, 1.0500000000000003], [0.0, 101.05000000000024, 0.0, 1.0500000000000003], [0.0, 101.02500000000023, 0.0, 1.0250000000000004], [0.0, 100.0, 0.0, 1.0500000000000003], [0.0, 100.0, 0.0, 1.0500000000000003], [0.0, 100.0, 0.0, 1.0500000000000003], [0.0, 100.0, 0.0, 1.0500000000000003], [0.0, 100.0, 0.0, 1.0500000000000003], [0.0, 100.0, 0.0, 1.0750000000000002], [0.0, 100.0, 0.0, 1.0250000000000004], [0.0, 100.0, 0.0, 1.0250000000000004], [0.0, 100.0, 0.0, 1.0500000000000003], [0.0, 100.0, 0.0, 1.0250000000000004], [0.0, 100.0, 0.0, 1.0500000000000003], [0.0, 101.05000000000024, 0.0, 1.0500000000000003], [0.0, 101.05000000000024, 0.0, 1.0500000000000003], [0.0, 101.02500000000023, 0.0, 1.0250000000000004], [0.0, 101.02500000000023, 0.0, 1.0250000000000004], [0.0, 101.02500000000023, 0.0, 1.0250000000000004], [2.1249999999999964, 96.82499999999928, 3.1749999999999927, 0.0], [1.8749999999999973, 100.12500000000003, 1.8749999999999973, 1.0000000000000004], [2.8999999999999937, 99.19999999999982, 1.7749999999999977, 0.9750000000000005], [2.6499999999999946, 156.55000000001286, 0.8000000000000004, 0.0], [2.1249999999999964, 157.150000000013, 0.7250000000000003, 0.0], [1.5249999999999986, 157.85000000001315, 0.6250000000000002, 0.0], [1.5749999999999984, 101.82500000000041, 3.4749999999999917, 0.0], [0.8000000000000004, 158.20000000001323, 1.0000000000000004, 0.0], [0.7000000000000003, 102.67500000000061, 4.399999999999995, 0.0], [0.1, 158.32500000001326, 1.5749999999999984, 0.0], [0.1, 158.40000000001328, 1.4999999999999987, 0.0], [0.125, 158.57500000001332, 1.2999999999999994, 0.0], [0.15, 158.12500000001322, 1.7249999999999979, 0.0], [0.0, 100.0, 49.949999999998234, 0.0], [0.0, 110.00000000000227, 54.57499999999797, 0.0], [0.0, 106.72500000000153, 52.79999999999807, 0.0], [0.0, 108.17500000000186, 53.34999999999804, 0.0], [0.025, 106.47500000000147, 12.225000000000106, 0.0], [0.07500000000000001, 104.20000000000095, 8.650000000000055, 0.0], [0.0, 103.72500000000085, 51.12499999999817, 0.0], [1.1, 160.00000000001364, 1.1, 0.0], [1.8499999999999974, 158.5000000000133, 0.35000000000000003, 0.0], [1.3249999999999993, 159.57500000001355, 0.9000000000000005, 0.0], [1.5249999999999986, 159.55000000001354, 1.0750000000000002, 0.0], [1.7499999999999978, 159.25000000001347, 1.0000000000000004, 0.0], [1.7499999999999978, 100.9000000000002, 3.349999999999992, 0.4500000000000001], [2.0749999999999966, 100.82500000000019, 3.049999999999993, 0.6750000000000003], [2.0749999999999966, 100.72500000000016, 3.124999999999993, 0.5750000000000002], [2.1249999999999964, 100.65000000000015, 3.099999999999993, 0.6250000000000002], [2.199999999999996, 100.80000000000018, 3.099999999999993, 0.5750000000000002], [2.3749999999999956, 100.67500000000015, 2.799999999999994, 0.7500000000000003], [2.4249999999999954, 100.77500000000018, 2.7249999999999943, 0.8000000000000004], [2.3499999999999956, 100.80000000000018, 2.024999999999997, 0.9750000000000005], [2.224999999999996, 100.80000000000018, 2.799999999999994, 0.8000000000000004], [1.974999999999997, 100.92500000000021, 3.0249999999999932, 0.7250000000000003], [2.299999999999996, 100.75000000000017, 2.9499999999999935, 0.7000000000000003], [2.4249999999999954, 100.9000000000002, 2.3499999999999956, 0.9250000000000005], [2.1749999999999963, 101.12500000000026, 2.6249999999999947, 0.8750000000000004], [2.274999999999996, 101.15000000000026, 1.15, 1.0250000000000004], [2.274999999999996, 101.12500000000026, 1.125, 1.0000000000000004], [1.8249999999999975, 94.47499999999874, 3.149999999999993, 0.6750000000000003], [0.9750000000000005, 99.975, 3.1749999999999927, 0.9000000000000005], [0.7250000000000003, 55.39999999999231, 4.349999999999994, 0.4250000000000001], [0.5000000000000001, 40.199999999993175, 0.5000000000000001, 0.5250000000000001], [0.5750000000000002, 40.39999999999316, 0.5750000000000002, 0.4000000000000001], [26.57499999999956, 40.79999999999314, 0.9250000000000005, 0.8000000000000004], [19.84999999999994, 40.82499999999314, 1.5499999999999985, 0.8250000000000004], [0.3, 40.94999999999313, 0.3, 0.9500000000000005]]
[57.818554398844135, 57.818554398844135, 538.31721776446, 479.2461524525502, 379.46537885373186, 367.19816592912764, 350.29085633149634, 350.2269142540333, 350.19108013049714, 442.6986325991824, 442.63994962069904, 552.7952206409094, 350.11618861477746, 442.63450744265066, 442.63994962069904, 350.10510890496556, 350.10510890496556, 442.6810231199256, 387.46842730929427, 442.7613093610473, 350.308752643139, 443.14599969006787, 350.83841615895096, 374.4143914117521, 500.59509863883153, 531.0994781991552, 509.2234458138069, 526.3108333896698, 514.7359588223131, 418.6459606386812, 463.24358333776706, 504.1220844504075, 482.1731634365282, 515.4750199449796, 507.7238918818809, 534.1357792230261, 504.1220844504075, 547.1240681047593, 493.28553735839614, 523.8278004608779, 351.1137087465359, 497.3915062808927, 523.8278004608779, 443.9545488310351, 443.9545488310351, 351.1137087465359, 431.50140825242613, 431.50140825242613, 431.50140825242613, 431.50140825242613, 431.50140825242613, 538.9915562195001, 341.177119914731, 341.177119914731, 431.50140825242613, 341.177119914731, 431.50140825242613, 443.9545488310351, 443.9545488310351, 351.1137087465359, 351.1137087465359, 351.1137087465359, 519.4519385776545, 407.65003120988405, 363.10883817021045, 53.510488274460045, 55.3675272367609, 56.78293479644479, 539.3653124430512, 54.949361767657614, 541.3387813093543, 56.128615028538896, 56.38073602355082, 56.70661555131267, 54.42079319576591, 57.818554398844135, 57.818554398844135, 57.818554398844135, 57.818554398844135, 560.6918736290595, 550.8369229129776, 57.818554398844135, 52.3964135330263, 57.672165531352114, 54.53662118322026, 50.92239106705031, 51.63717472482646, 542.8449426663901, 506.1976137889279, 512.9820504231471, 547.339785615097, 550.7435766535827, 449.93619497678384, 475.6267329804123, 429.21235929521725, 481.3279021003127, 489.2251116466292, 523.5101121649168, 463.2317245806367, 473.1234041126976, 386.3787859675938, 302.6033275267504, 475.69343940414933, 435.3973742203867, 548.016721318525, 44.21540678501438, 52.404557728173394, 3.0149190358761233, 375.2804567373666, 0.3387201335915563]
over time 08--01-05

Process finished with exit code 0
